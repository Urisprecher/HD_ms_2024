{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fb632cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix \n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.manifold import TSNE\n",
    "from colour import Color\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix \n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.manifold import TSNE\n",
    "from colour import Color\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "import sklearn.linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import make_moons, make_blobs\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix \n",
    "from psynlig import plot_correlation_heatmap\n",
    "from scipy.stats import pearsonr\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.tools import FigureFactory as FF\n",
    "import chart_studio as cs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import chart_studio.plotly as py\n",
    "from plotly.offline import iplot\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "%matplotlib inline  \n",
    "from plotly import __version__ \n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import cufflinks as cf\n",
    "init_notebook_mode(connected=True)\n",
    "cf.go_offline()\n",
    "import chart_studio.plotly as py\n",
    "from sklearn import preprocessing\n",
    "from pandas.plotting import scatter_matrix \n",
    "from psynlig import plot_correlation_heatmap\n",
    "from scipy.stats import pearsonr\n",
    "import kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6d00fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d56f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_dataframe(df, group_col):\n",
    "\n",
    "    grouped_df = df.groupby(group_col)\n",
    "   \n",
    "    agg_dict = {}\n",
    "   \n",
    "    for col in df.columns:\n",
    "        if col != group_col:\n",
    "            agg_dict[col] = [\n",
    "                ('count', 'count'),\n",
    "                ('mean', 'mean'),\n",
    "                ('std', 'std'),\n",
    "                ('min', 'min'),\n",
    "                ('25%', lambda x: np.quantile(x, 0.25)),\n",
    "                ('median', 'median'),\n",
    "                ('75%', lambda x: np.quantile(x, 0.75)),\n",
    "                ('max', 'max')\n",
    "                \n",
    "            ]\n",
    "   \n",
    "    summary_df = grouped_df.agg(agg_dict)\n",
    "   \n",
    "    summary_df.columns = [f'{col}_{stat}' for col, stat in summary_df.columns]\n",
    "   \n",
    "    summary_df.index.name = group_col\n",
    "   \n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f13d8d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_check_if_hc(frame):\n",
    "    frame = frame.drop(columns=['Local Outlier Factor 30', 'Local Outlier Factor 30_outliers',\n",
    "       'Local Outlier Factor 10', 'Local Outlier Factor 10_outliers',\n",
    "       'Local Outlier Factor 8', 'Local Outlier Factor 8_outliers', 'group', 'group_p', 'Cell_id',\n",
    "       'group_with_id', 'group_with_p'])\n",
    "    print(\"frame_ready\")\n",
    "    for col in frame:\n",
    "            \n",
    "            plt.hist(frame[col])\n",
    "            plt.title(f\"Histogram of hc({col})\")\n",
    "            plt.xlabel(f\"hc({col})\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.show()\n",
    "            plt.savefig(path + '//' + f\"hist_hc{col}.pdf\", dpi = 600)\n",
    "            plt.close()\n",
    "            print(\"hist_done!\")\n",
    "            plt.figure()\n",
    "            scipy.stats.probplot(frame[col], dist=\"norm\", plot=plt)\n",
    "            plt.title(f\"Q-Q-{col}\")\n",
    "            plt.show\n",
    "            plt.savefig(path + '//' + f\"Q-Q_hc{col}.pdf\", dpi = 600)\n",
    "            plt.close()\n",
    "            print(\"qq_done:)\")\n",
    "            plt.figure()\n",
    "            sns.distplot(frame[col], kde = True, color ='red', bins = 30)\n",
    "            plt.title(f\"dist-{col}\")\n",
    "            plt.show\n",
    "            plt.savefig(path + '//' + f\"dist_hc{col}.pdf\", dpi = 600)\n",
    "            plt.close()\n",
    "            print(\"on it:)\")\n",
    "            print(\"done:)\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df2a5188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_check_if_max(frame):\n",
    "    \n",
    "    print(\"frame_ready\")\n",
    "    for col in frame:\n",
    "            plt.hist(frame[col])\n",
    "            plt.title(f\"Histogram of max({col})\")\n",
    "            plt.xlabel(f\"max({col})\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.show()\n",
    "            plt.savefig(path + '//' + f\"hist_max{col}.pdf\", dpi = 600)\n",
    "            plt.close()\n",
    "            print(\"hist_done!\")\n",
    "            plt.figure()\n",
    "            scipy.stats.probplot(frame[col], dist=\"norm\", plot=plt)\n",
    "            plt.title(f\"Q-Q-{col}\")\n",
    "            plt.show\n",
    "            plt.savefig(path + '//' + f\"Q-Q_max{col}.pdf\", dpi = 600)\n",
    "            plt.close()\n",
    "            print(\"qq_done:)\")\n",
    "            plt.figure()\n",
    "            sns.distplot(frame[col], kde = True, color ='red', bins = 30)\n",
    "            plt.title(f\"dist-{col}\")\n",
    "            plt.show\n",
    "            plt.savefig(path + '//' + f\"dist_max{col}.pdf\", dpi = 600)\n",
    "            plt.close()\n",
    "            print(\"on it:)\")\n",
    "            print(\"done:)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d529670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_check_if_log(frame):\n",
    "    \n",
    "    print(\"frame_ready\")\n",
    "    for col in frame:\n",
    "            plt.hist(frame[col])\n",
    "            plt.title(f\"Histogram of log({col})\")\n",
    "            plt.xlabel(f\"log({col})\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.show()\n",
    "            plt.savefig(path + '//' + f\"hist_log{col}.pdf\", dpi = 600)\n",
    "            plt.close()\n",
    "            print(\"hist_done!\")\n",
    "            plt.figure()\n",
    "            scipy.stats.probplot(frame[col], dist=\"norm\", plot=plt)\n",
    "            plt.title(f\"Q-Q-{col}\")\n",
    "            plt.show\n",
    "            plt.savefig(path + '//' + f\"Q-Q_log{col}.pdf\", dpi = 600)\n",
    "            plt.close()\n",
    "            print(\"qq_done:)\")\n",
    "            plt.figure()\n",
    "            sns.distplot(frame[col], kde = True, color ='red', bins = 30)\n",
    "            plt.title(f\"dist-{col}\")\n",
    "            plt.show\n",
    "            plt.savefig(path + '//' + f\"dist_log{col}.pdf\", dpi = 600)\n",
    "            plt.close()\n",
    "            print(\"on it:)\")\n",
    "            print(\"done:)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f870bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_check_if_log_2(frame):\n",
    "    \n",
    "    print(\"frame_ready\")\n",
    "    for col in frame:\n",
    "            plt.hist(frame[col])\n",
    "            plt.title(f\"Histogram of log+1({col})\")\n",
    "            plt.xlabel(f\"log+1({col})\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.show()\n",
    "            plt.savefig(path + '//' + f\"hist_log+1{col}.pdf\", dpi = 600)\n",
    "            plt.close()\n",
    "            print(\"hist_done!\")\n",
    "            plt.figure()\n",
    "            scipy.stats.probplot(frame[col], dist=\"norm\", plot=plt)\n",
    "            plt.title(f\"Q-Q-{col}\")\n",
    "            plt.show\n",
    "            plt.savefig(path + '//' + f\"Q-Q_log+1{col}.pdf\", dpi = 600)\n",
    "            plt.close()\n",
    "            print(\"qq_done:)\")\n",
    "            plt.figure()\n",
    "            sns.distplot(frame[col], kde = True, color ='red', bins = 30)\n",
    "            plt.title(f\"dist-{col}\")\n",
    "            plt.show\n",
    "            plt.savefig(path + '//' + f\"dist_log+1{col}.pdf\", dpi = 600)\n",
    "            plt.close()\n",
    "            print(\"on it:)\")\n",
    "            print(\"done:)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7546cc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_function(list):\n",
    "    for item in list:\n",
    "        name = [i for i in globals() if globals()[i] is item][0]\n",
    "        item1 = list[0]\n",
    "        item2 = list[1]\n",
    "        twosample_results = scipy.stats.ttest_ind(item1, item2, equal_var=False, permutations=1000)\n",
    "        matrix_twosample = [\n",
    "        ['', 'Test Statistic', 'p-value'],\n",
    "        ['{}'.format(name), twosample_results[0], twosample_results[1]]\n",
    "    ]\n",
    "        twosample_table = FF.create_table(matrix_twosample, index=True)\n",
    "        cf.go_offline()\n",
    "        iplot(twosample_table, filename='{}twosample-table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16f80c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "### mfn2 \n",
    "add_plate_column('C:/Users/Uri8s/MFN2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff8736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## mfn2 res path\n",
    "path = ('MFN2_res') \n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "    print('Output folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48af69f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mfn2\n",
    "all_files = glob.glob('C:/Users/Uri8s/output_mfn2/*.csv')\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    li.append(df)\n",
    "\n",
    "mfn2_df = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530b8277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#index frame\n",
    "mfn2_df[\"group\"] = mfn2_df[\"Severity\"].astype(str) + mfn2_df[\"Compound\"].astype(str)\n",
    "mfn2_df.set_index([\"group\"], inplace = True,\n",
    "                            append = True, drop = False)\n",
    "mfn2_df[\"group_with_id\"] = mfn2_df[\"Severity\"].astype(str) + mfn2_df[\"Compound\"].astype(str) + mfn2_df[\"Cell ID\"].astype(str) \n",
    "mfn2_df.set_index([\"group_with_id\"], inplace = True,\n",
    "                            append = True, drop = False)\n",
    "mfn2_df[\"group_with_p\"] = mfn2_df[\"Severity\"].astype(str) + mfn2_df[\"Compound\"].astype(str) + mfn2_df[\"Cell ID\"].astype(str) + mfn2_df[\"plate\"].astype(str)\n",
    "mfn2_df.set_index([\"group_with_p\"], inplace = True,\n",
    "                            append = True, drop = False)\n",
    "mfn2_df[\"group_p\"] = mfn2_df[\"Severity\"].astype(str) + mfn2_df[\"Compound\"].astype(str) + mfn2_df[\"plate\"].astype(str)\n",
    "mfn2_df.set_index([\"group_p\"], inplace = True,\n",
    "                            append = True, drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d66578b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfn2_df[\"group\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da774fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfn2_df[\"plate\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611f6eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_types =  mfn2_df[\"plate\"].values\n",
    "sns.histplot(plate_types)\n",
    "plt.show()\n",
    "print(f'Total number of cell types {len(plate_types)}')\n",
    "mfn2_df = mfn2_df.loc[plate_types != 'p1']\n",
    "sns.histplot(mfn2_df[\"plate\"].values)\n",
    "plt.show()\n",
    "print(f'Total number of cells {len(mfn2_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67872785",
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_types =  mfn2_df[\"plate\"].values\n",
    "sns.histplot(plate_types)\n",
    "plt.show()\n",
    "print(f'Total number of cell types {len(plate_types)}')\n",
    "mfn2_df = mfn2_df.loc[plate_types != 'p2']\n",
    "sns.histplot(mfn2_df[\"plate\"].values)\n",
    "plt.show()\n",
    "print(f'Total number of cells {len(mfn2_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294843f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_types =  mfn2_df[\"plate\"].values\n",
    "sns.histplot(plate_types)\n",
    "plt.show()\n",
    "print(f'Total number of cell types {len(plate_types)}')\n",
    "mfn2_df = mfn2_df.loc[plate_types != 'p3']\n",
    "sns.histplot(mfn2_df[\"plate\"].values)\n",
    "plt.show()\n",
    "print(f'Total number of cells {len(mfn2_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e78ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfn2_df[\"group\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5f1db4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#summary 1\n",
    "mfn2_df_sum = mfn2_df.drop(columns=[\"group\", \"group_with_id\",\"group_with_p\", \"group_p\", \"Cell ID\", \"plate\", \"Row\", \"Column\", \"Cell Type\",\n",
    "                                    \"Plane\", \"Timepoint\", \"Height [Âµm]\", \"Time [s]\", \"Compound\", \"Severity\", \"pos\" ])\n",
    "mfn2_df_sum = mfn2_df_sum.reset_index()\n",
    "mfn2_df_sum = mfn2_df_sum.drop(columns=[\"group_with_id\",\"group\", \"group_p\", \"level_0\"])\n",
    "sum1 = summarize_dataframe(mfn2_df_sum, \"group_with_p\")\n",
    "sum1 = sum1.reset_index()\n",
    "sum1.to_csv(path + \"//\" + 'mfn2_sum1a.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00f0c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear low and high cell count\n",
    "cell_count =  mfn2_df[\"all_cells - Number of Objects\"].values\n",
    "sns.histplot(cell_count)\n",
    "plt.show()\n",
    "mfn2_df = mfn2_df.loc[cell_count<1200]\n",
    "sns.histplot(mfn2_df[\"all_cells - Number of Objects\"].values)\n",
    "plt.show()\n",
    "mfn2_df = mfn2_df.loc[cell_count>200]\n",
    "sns.histplot(mfn2_df[\"all_cells - Number of Objects\"].values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e493a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfn2_df.to_csv(path + \"//\" + 'mfn2_df1.csv', index=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a6e945",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count per group\n",
    "mfn2_df_count = mfn2_df.groupby(level=1).mean()\n",
    "mfn2_df_count = mfn2_df_count.reset_index()\n",
    "count_cells = px.bar(mfn2_df_count, x = \"group\", y = \"all_cells - Number of Objects\",\n",
    "            barmode = 'group')\n",
    "\n",
    "count_cells.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99966ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep features by corelation analysis\n",
    "mfn2_df2 = mfn2_df[['group', 'group_with_id', \"group_with_p\", \"Cell ID\", \"group_p\",\n",
    "                           \"spots_chanel_4_final - Intensity_Spot chanel_4_final Mean - Mean per Well\", \"total_ir_chanel_4_normalized\"]]\n",
    "mfn2_df2.columns = [str(col) + '_mfn2' for col in mfn2_df2.columns]\n",
    "mfn2_df2 = mfn2_df2.rename(\n",
    "     columns={\"group_mfn2\":\"group\",\n",
    "              \"group_with_id_mfn2\":\"group_with_id\",\n",
    "              \"group_with_p_mfn2\":\"group_with_p\",\n",
    "              \"group_p_mfn2\":\"group_p\",\n",
    "              \"Cell ID_mfn2\":\"Cell_id\",\n",
    "              \"spots_chanel_4_final - Intensity_Spot chanel_4_final Mean - Mean per Well_mfn2\":\"mfn2_intensity\",\n",
    "              \"total_ir_chanel_4_normalized_mfn2\":\"mfn2_area\"})\n",
    "print(mfn2_df2)\n",
    "mfn2_df2.to_csv(path + \"//\" + 'mfn2_df2.csv', index=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a935338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary 2\n",
    "mfn2_df_sum = mfn2_df2.drop(columns=[\"group\", \"group_with_id\",\"group_with_p\", \"group_p\"])\n",
    "mfn2_df_sum = mfn2_df_sum.reset_index()\n",
    "mfn2_df_sum = mfn2_df_sum.drop(columns=[\"Cell_id\", \"group_with_id\",\"group\", \"level_0\", \"group_p\"])\n",
    "sum2 = summarize_dataframe(mfn2_df_sum, \"group_with_p\")\n",
    "sum2 = sum2.reset_index()\n",
    "sum2.to_csv(path + \"//\" + 'mfn2_sum2b.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcade0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTLIER DETECTION MODE \n",
    "DataFrame_OutliersDetections = mfn2_df2.copy()\n",
    "types = mfn2_df2[\"group\"].unique()\n",
    "mask = []\n",
    "features = mfn2_df2.columns[5:]\n",
    "print(types)\n",
    "\n",
    "\n",
    "detector_list = [\n",
    "    \n",
    "        (\n",
    "        \"Local Outlier Factor 8\",\n",
    "        LocalOutlierFactor(n_neighbors=8),\n",
    "    ),\n",
    "    (\n",
    "        \"Local Outlier Factor 10\",\n",
    "        LocalOutlierFactor(n_neighbors=10),\n",
    "    ),\n",
    "        (\n",
    "         \"Local Outlier Factor 30\",\n",
    "        LocalOutlierFactor(n_neighbors=30),\n",
    "        ),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a188efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, algorithm in detector_list:\n",
    "    errors = np.full(len(DataFrame_OutliersDetections),fill_value=np.nan)\n",
    "    outliers = np.full(len(DataFrame_OutliersDetections),fill_value=np.nan)\n",
    "\n",
    "    for type in types:\n",
    "        x = DataFrame_OutliersDetections.loc[:,features].values\n",
    "        F = x.sum(1)\n",
    "        mask = np.zeros(x.shape[0])\n",
    "        mask[np.isfinite(F)] = 1\n",
    "        mask_type = mask * np.array(DataFrame_OutliersDetections[\"group\"] == type)\n",
    "        Curr_df = DataFrame_OutliersDetections.loc[mask_type==1,features]\n",
    "\n",
    "        x = Curr_df.values\n",
    "        if name == 'pca_approx':\n",
    "\n",
    "            x = StandardScaler().fit_transform(x)\n",
    "            lower_dimensional_data = algorithm.fit_transform(x)\n",
    "            pproximation = algorithm.inverse_transform(lower_dimensional_data)\n",
    "\n",
    "            err = np.linalg.norm(x-pproximation,2,axis=1)\n",
    "\n",
    "            errors[mask_type==1] = err\n",
    "            outliers[mask_type==1] = (err < 5) * 2 - 1\n",
    "            if False:\n",
    "                plt.scatter(lower_dimensional_data[:,0],lower_dimensional_data[:,1],c=err>5)\n",
    "                plt.title(type)\n",
    "                plt.show()\n",
    "        else:\n",
    "            algorithm.fit(x)\n",
    "            if name == \"Robust covariance\":\n",
    "                errors[mask_type==1] = algorithm.mahalanobis(x)\n",
    "                outliers[mask_type==1] = algorithm.predict(x)\n",
    "\n",
    "            if  \"Local Outlier Factor\" in name:\n",
    "                errors[mask_type==1] = algorithm.negative_outlier_factor_\n",
    "                outliers[mask_type==1] = algorithm.fit_predict(x)\n",
    "            else:\n",
    "                y_pred = algorithm.fit(x).predict(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    DataFrame_OutliersDetections[name] = errors\n",
    "    DataFrame_OutliersDetections[f'{name}_outliers'] = outliers\n",
    "    DataFrame_OutliersDetections.set_index(name, inplace = True,\n",
    "                            append = True, drop = False)\n",
    "\n",
    "    DataFrame_OutliersDetections.to_csv(path + \"//\" + 'mfn2_df4.csv', index=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4d6601",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame_OutliersDetections[\"group\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f854d0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = DataFrame_OutliersDetections[DataFrame_OutliersDetections['Local Outlier Factor 10_outliers'] == 1]\n",
    "df_clean[\"group\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a74b3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## export for integ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c74ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_integ = df_clean.groupby(level=2).mean()\n",
    "df_integ = df_integ.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f69c7aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv(path + \"//\" + 'mfn2_df5.csv', index=None)    \n",
    "df_integ.to_csv(path + \"//\" + 'mfn2_df_integ.csv', index=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c92f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2556ed88",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Uri8s\\AppData\\Local\\Temp/ipykernel_28376/1008584565.py:3: FutureWarning:\n",
      "\n",
      "Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#hc mean norm\n",
    "hc = df_clean[(df_clean['group'] == 'HCDMSO')]\n",
    "hc_mean = hc.mean()\n",
    "Nh_df = df_clean/hc_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "981d84e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log = df_clean.drop(columns=[\"group_with_p\", \"group\", \"group_with_id\", \"group_p\",\n",
    "                           'Local Outlier Factor 8', \"Cell_id\",\n",
    "       'Local Outlier Factor 8_outliers', 'Local Outlier Factor 10',\n",
    "       'Local Outlier Factor 10_outliers', 'Local Outlier Factor 30',\n",
    "       'Local Outlier Factor 30_outliers'])\n",
    "for col in df_log:\n",
    "    df_log[col] = np.log(df_log[col])\n",
    "    NL_df = df_log.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "72815a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log_2 = df_clean.drop(columns=[\"group_with_p\", \"group\", \"group_with_id\", \"group_p\",\n",
    "                           'Local Outlier Factor 8', \"Cell_id\",\n",
    "       'Local Outlier Factor 8_outliers', 'Local Outlier Factor 10',\n",
    "       'Local Outlier Factor 10_outliers', 'Local Outlier Factor 30',\n",
    "       'Local Outlier Factor 30_outliers'])\n",
    "for col in df_log_2:\n",
    "        df_log_2[col] = np.log(1+df_log_2[col]-min(df_log_2[col]))\n",
    "        NL2_df = df_log_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ca10dd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max_scaled = df_clean.drop(columns=[\"group_with_p\", \"group\", \"group_with_id\", \"group_p\",\n",
    "                           'Local Outlier Factor 8', \"Cell_id\",\n",
    "       'Local Outlier Factor 8_outliers', 'Local Outlier Factor 10',\n",
    "       'Local Outlier Factor 10_outliers', 'Local Outlier Factor 30',\n",
    "       'Local Outlier Factor 30_outliers'])\n",
    "for column in df_max_scaled.columns:\n",
    "        df_max_scaled[column] = df_max_scaled[column]  / df_max_scaled[column].abs().max()\n",
    "        NM_df = df_max_scaled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cd339918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#initialze excel writer\n",
    "writer = pd.ExcelWriter(path + '//' + 'mfn2_normalzied-excel.xlsx', engine='xlsxwriter')\n",
    "\n",
    "frames = {'hc': Nh_df, 'log': NL_df, 'log2':NL2_df,\n",
    "              'max': NM_df}\n",
    "\n",
    "for sheet, frame in  frames.items():\n",
    "    frame.to_excel(writer, sheet_name = sheet)\n",
    "\n",
    "writer.save()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d55dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feat QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe35d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_var_calc = df_clean.copy()\n",
    "df_var_calc = df_var_calc.drop(columns=['Local Outlier Factor 30', 'Local Outlier Factor 30_outliers',\n",
    "       'Local Outlier Factor 10', 'Local Outlier Factor 10_outliers',\n",
    "       'Local Outlier Factor 8', 'Local Outlier Factor 8_outliers', 'group', \"Cell_id\",\n",
    "       'group_with_id', 'group_with_p', 'group_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847a3126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variance each feature\n",
    "feature_variances = df_var_calc.var()\n",
    "\n",
    "##standard deviation each feature\n",
    "feature_std_devs = df_var_calc.std()\n",
    "\n",
    "###CV each feature\n",
    "feature_cv = df_var_calc.std() / df_var_calc.mean()\n",
    "\n",
    "###printresults\n",
    "print(\"Feature Variance:\")\n",
    "print(feature_variances)\n",
    "\n",
    "print(\"\\nFeature Standard Deviation:\")\n",
    "print(feature_std_devs)\n",
    "\n",
    "print(\"\\nFeature Coefficient of Variation (CV):\")\n",
    "print(feature_cv)\n",
    "\n",
    "\n",
    "feature_variances.to_csv(path + \"//\" + 'mfn2-feature_variances.csv', index=None)\n",
    "feature_std_devs.to_csv(path + \"//\" + 'mfn2-feature_std_devs.csv', index=None)\n",
    "feature_cv.to_csv(path + \"//\" + 'mfn2-feature_coefficient_of_variation.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af53f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "# Plot feature variances\n",
    "plt.bar(range(len(feature_variances)), feature_variances, align='center')\n",
    "plt.xticks(range(len(feature_variances)), feature_variances.index, rotation=45)\n",
    "plt.title('Feature Variance')\n",
    "plt.ylabel('Variance')\n",
    "plt.xlabel('features')\n",
    "plt.show()\n",
    "plt.savefig(path + '//' + \"mfn2-feature_var.pdf\", dpi = 600)\n",
    "plt.close()\n",
    "print(\"var_done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c4ea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature standard deviations\n",
    "plt.bar(range(len(feature_std_devs)), feature_std_devs, align='center')\n",
    "plt.xticks(range(len(feature_std_devs)), feature_std_devs.index, rotation=45)\n",
    "plt.title('Feature Standard Deviation')\n",
    "plt.ylabel('Standard Deviation')\n",
    "plt.xlabel('features')\n",
    "plt.show()\n",
    "plt.savefig(path + '//' + \"mfn2-feature_sd.pdf\", dpi = 600)\n",
    "plt.close()\n",
    "print(\"sd_done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6e863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature coefficient of variation\n",
    "plt.bar(range(len(feature_cv)), feature_cv, align='center')\n",
    "plt.xticks(range(len(feature_cv)), feature_cv.index, rotation=45)\n",
    "plt.title('Feature Coefficient of Variation (CV)')\n",
    "plt.ylabel('Coefficient of Variation')\n",
    "plt.xlabel('features')\n",
    "plt.show()\n",
    "plt.savefig(path + '//' + \"mfn2-feature_cv.pdf\", dpi = 600)\n",
    "plt.close()\n",
    "print(\"cv_done!\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "217575b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### make sure to groupby mean before plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb2246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_log.groupby(level=5).mean()\n",
    "df_plot = df_plot.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c775a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_plot:\n",
    "    \n",
    "    fig = px.bar(df_plot, x = \"group_with_id\", y = col,\n",
    "            barmode = 'group')\n",
    "    fig.write_image(path + '//' + f\"{col}mid_plot_image.pdf\", engine=\"kaleido\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78824cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_check_if_hc(Nh_df)\n",
    "dist_check_if_log(df_log)\n",
    "dist_check_if_log_2(df_log_2)\n",
    "dist_check_if_max(df_max_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf6c275",
   "metadata": {},
   "outputs": [],
   "source": [
    "### vis+stats_marker conclusions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eec2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = df_log.copy()\n",
    "df_stats = df_stats.reset_index()\n",
    "df_stats = df_stats.drop(columns=['Local Outlier Factor 30', 'Local Outlier Factor 10', 'Local Outlier Factor 8', 'level_0'])\n",
    "df_stats = df_stats.reset_index()\n",
    "df_stats = df_stats.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ce05b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df_stats.groupby(\"group\").mean()\n",
    "grouped_df.fillna(0, inplace=True)\n",
    "grouped_df =(grouped_df-grouped_df.mean())/grouped_df.std()\n",
    "###heatmap \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(grouped_df, cmap='BuPu')\n",
    "sns.set_style(\"white\")\n",
    "SMALL_SIZE =3\n",
    "MEDIUM_SIZE = 5\n",
    "BIGGER_SIZE = 12\n",
    "plt.rc('font', size=SMALL_SIZE)         \n",
    "plt.rc('axes', titlesize=SMALL_SIZE)    \n",
    "plt.rc('axes', labelsize=SMALL_SIZE)   \n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    \n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)   \n",
    "plt.rc('legend', fontsize=SMALL_SIZE)  \n",
    "plt.rc('figure', titlesize=BIGGER_SIZE) \n",
    "cax = plt.gcf().axes[0]\n",
    "cax.tick_params(labelsize=6)\n",
    "plt.yticks(rotation=\"horizontal\")\n",
    "plt.xticks(rotation=\"vertical\")\n",
    "plt.margins(0.1)\n",
    "plt.subplots_adjust(bottom=0.3)\n",
    "plt.savefig(path + '//' + \"heatmap_mfn2.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e4b9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### box plots all feat\n",
    "for col in df_stats.columns[3:]:\n",
    "    \n",
    "    fig = px.box(df_stats, x = \"group\", y = col, hover_data=[\"group_with_p\"],\n",
    "                 points=\"all\", color=\"group\",\n",
    "            notched=True)\n",
    "    fig.update_xaxes(categoryorder='array', categoryarray= ['HCDMSO', 'PREDMSO', 'PREmdivi1 25uM',\n",
    "                                                            'MDMSO', 'Mmdivi1 25uM', \n",
    "                                                           'SDMSO', 'Smdivi1 25uM'])\n",
    "    fig.update_traces(quartilemethod=\"inclusive\") # or \"inclusive\", or \"linear\" by default\n",
    "    fig.update_layout(\n",
    "    font_family=\"Arial\",\n",
    "    font_color=\"Black\",\n",
    "    font_size=20,\n",
    "    font=dict(\n",
    "        family=\"Arial\",\n",
    "        size=20,\n",
    "        color=\"Black\"\n",
    "    )\n",
    ")\n",
    "\n",
    "    fig.write_image(path + '//' + f\"{col}box_plot_image.pdf\", engine=\"kaleido\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536eaf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "49872c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEF GROUPS\n",
    "#hc\n",
    "HC = df_stats[(df_stats['group'] == 'HCDMSO')]\n",
    "HC_intensity_mean = HC[[\"mfn2_intensity\"]]\n",
    "HC_area = HC[[\"mfn2_area\"]]\n",
    "#ds\n",
    "#Sev\n",
    "S = df_stats[(df_stats['group'] == 'SDMSO')]\n",
    "S_intensity_mean = S[[\"mfn2_intensity\"]]\n",
    "S_area = S[[\"mfn2_area\"]]\n",
    "#Mild\n",
    "M = df_stats[(df_stats['group'] == 'MDMSO')]\n",
    "M_intensity_mean = M[[\"mfn2_intensity\"]]\n",
    "M_area = M[[\"mfn2_area\"]]\n",
    "#Pre\n",
    "P = df_stats[(df_stats['group'] == 'PREDMSO')]\n",
    "P_intensity_mean = P[[\"mfn2_intensity\"]]\n",
    "P_area = P[[\"mfn2_area\"]]\n",
    "#dsT\n",
    "#Sev\n",
    "ST = df_stats[(df_stats['group'] == 'Smdivi1 25uM')]\n",
    "ST_intensity_mean = ST[[\"mfn2_intensity\"]]\n",
    "ST_area = ST[[\"mfn2_area\"]]\n",
    "#Mild\n",
    "MT = df_stats[(df_stats['group'] == 'Mmdivi1 25uM')]\n",
    "MT_intensity_mean = MT[[\"mfn2_intensity\"]]\n",
    "MT_area = MT[[\"mfn2_area\"]]\n",
    "#Pre\n",
    "PT = df_stats[(df_stats['group'] == 'PREmdivi1 25uM')]\n",
    "PT_intensity_mean = PT[[\"mfn2_intensity\"]]\n",
    "PT_area = PT[[\"mfn2_area\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "db5540fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hc vs ds \n",
    "one_list = [(S_intensity_mean), (HC_intensity_mean)]\n",
    "two_list = [(M_intensity_mean), (HC_intensity_mean)]\n",
    "three_list = [(P_intensity_mean), (HC_intensity_mean)]\n",
    "#ds vs dst \n",
    "one2_list = [(S_intensity_mean), (ST_intensity_mean)]\n",
    "two2_list = [(M_intensity_mean), (MT_intensity_mean)]\n",
    "three2_list = [(P_intensity_mean), (PT_intensity_mean)]\n",
    "#DS vs ds \n",
    "one3_list = [ (S_intensity_mean), (M_intensity_mean)]\n",
    "two3_list = [(S_intensity_mean), (P_intensity_mean)]\n",
    "three3_list = [(M_intensity_mean), (P_intensity_mean)]\n",
    "#general lists \n",
    "all_list = (one_list, two_list, three_list)\n",
    "sec_list = (one2_list, two2_list, three2_list)\n",
    "t_list = (one3_list, two3_list, three3_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82696dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in all_list:\n",
    "    t_function(x)\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16a703d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in sec_list:\n",
    "    t_function(x)\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f906eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in t_list:\n",
    "    t_function(x)\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7c2221",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
