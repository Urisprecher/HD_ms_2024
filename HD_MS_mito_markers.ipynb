{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178511a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix \n",
    "%matplotlib inline\n",
    "# from pptx import Presentation\n",
    "# from pptx.util import Inches\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.manifold import TSNE\n",
    "from colour import Color\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "import sklearn.linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import make_moons, make_blobs\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "#from sklearn.linear_model import SGDOneClassSVM\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix \n",
    "from psynlig import plot_correlation_heatmap\n",
    "import pingouin as pg\n",
    "from scipy.stats import pearsonr\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.tools import FigureFactory as FF\n",
    "import chart_studio as cs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import chart_studio.plotly as py\n",
    "from plotly.offline import iplot\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "%matplotlib inline  \n",
    "from plotly import __version__ \n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import cufflinks as cf\n",
    "init_notebook_mode(connected=True)\n",
    "cf.go_offline()\n",
    "import chart_studio.plotly as py\n",
    "from sklearn import preprocessing\n",
    "from pandas.plotting import scatter_matrix \n",
    "from psynlig import plot_correlation_heatmap\n",
    "import pingouin as pg\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52c6916",
   "metadata": {},
   "outputs": [],
   "source": [
    "##functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51737ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_dataframe(df, group_col):\n",
    "    \"\"\"\n",
    "    This function takes a pandas DataFrame and a column to group by as inputs and returns\n",
    "    a summary DataFrame with statistical parameters for each group.\n",
    "    \"\"\"\n",
    "    # Group the DataFrame by the specified column\n",
    "    grouped_df = df.groupby(group_col)\n",
    "   \n",
    "    # Define a dictionary to hold the statistical parameters to compute for each column\n",
    "    agg_dict = {}\n",
    "   \n",
    "    # Loop over the columns in the DataFrame and add the statistical parameters to the agg_dict\n",
    "    for col in df.columns:\n",
    "        if col != group_col:\n",
    "            agg_dict[col] = [\n",
    "                ('count', 'count'),\n",
    "                ('mean', 'mean'),\n",
    "                ('std', 'std'),\n",
    "                ('min', 'min'),\n",
    "                ('25%', lambda x: np.quantile(x, 0.25)),\n",
    "                ('median', 'median'),\n",
    "                ('75%', lambda x: np.quantile(x, 0.75)),\n",
    "                ('max', 'max')\n",
    "                \n",
    "            ]\n",
    "   \n",
    "    # Compute the summary statistics for each group and column using the agg_dict\n",
    "    summary_df = grouped_df.agg(agg_dict)\n",
    "   \n",
    "    # Flatten the multi-index column names into a single level\n",
    "    summary_df.columns = [f'{col}_{stat}' for col, stat in summary_df.columns]\n",
    "   \n",
    "    # Rename the index column\n",
    "    summary_df.index.name = group_col\n",
    "   \n",
    "    # Return the summary DataFrame\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8469b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_plate_column(folder_path):\n",
    "    files = os.listdir(folder_path)\n",
    "    output_folder = os.path.join(folder_path, \"output\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "   \n",
    "    for i, file in enumerate(files):\n",
    "        if file.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            output_path = os.path.join(output_folder, file)\n",
    "           \n",
    "            df = pd.read_csv(file_path)\n",
    "            df.insert(0, \"plate\", f\"p{i+1}\")\n",
    "            df['Row'] = 'r' + df['Row'].astype(str)\n",
    "            df['Column'] = 'c' + df['Column'].astype(str)\n",
    "            df[\"pos\"] = df[\"Row\"].astype(str) + df[\"Column\"].astype(str)  + df[\"plate\"].astype(str) \n",
    "            df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e900e7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_exp_column_to_csv_files(input_path, output_path):\n",
    "    #  output folder \n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "   \n",
    "    # csv input folder\n",
    "    csv_files = [file for file in os.listdir(input_path) if file.endswith('.csv')]\n",
    "   \n",
    "    for file in csv_files:\n",
    "        # Read the CSV file\n",
    "        file_path = os.path.join(input_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "       \n",
    "        # letters for the EXP column\n",
    "        exp_value = file[7:10] \n",
    "       \n",
    "        #  add EXP column to dataFrame\n",
    "        df['EXP'] = exp_value\n",
    "       \n",
    "        # Save\n",
    "        output_file_path = os.path.join(output_path, file)\n",
    "        df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1294600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output folder created\n"
     ]
    }
   ],
   "source": [
    "path = ('RESULTS_mito_markers_feat_seelction') \n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "    print('Output folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc16f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DRP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e7941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob('noam_may_analysis_fold1/DRP1/*.csv')\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    li.append(df)\n",
    "\n",
    "drp1_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "# SCAT_HEAT_DATA.set_index([\"Cell Type\", \"CELL ID\", \"Compound\", 'PC'], inplace = True,\n",
    "#                            append = True, drop = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb21c28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove treated data\n",
    "cell_types =  drp1_df[\"Compound\"].values\n",
    "sns.histplot(cell_types)\n",
    "plt.show()\n",
    "print(f'Total number of cell types {len(cell_types)}')\n",
    "drp1_df = drp1_df.loc[cell_types != 'mdivi1 25uM']\n",
    "sns.histplot(drp1_df[\"Compound\"].values)\n",
    "plt.show()\n",
    "print(f'Total number of cells {len(drp1_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054cd6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##define groups \n",
    "df_h = drp1_df[(drp1_df[\"Severity\"] == 'HC')] \n",
    "df_s = drp1_df[(drp1_df[\"Severity\"] == 'S')]\n",
    "frame_drp = (df_h, df_s)\n",
    "frame_drp_f = pd.concat(frame_drp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b627e091",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MiguelW12\\AppData\\Local\\Temp\\ipykernel_9812\\3460966092.py:5: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  CLEAN_dfheatmapREAL_drp = HEAT_DATA_drp1.groupby(level=1).mean()\n"
     ]
    }
   ],
   "source": [
    "HEAT_DATA_drp1 = frame_drp_f.copy()\n",
    "HEAT_DATA_drp1[\"group_with_id\"] = HEAT_DATA_drp1[\"Cell ID\"].astype(str) + HEAT_DATA_drp1[\"Cell Type\"].astype(str) \n",
    "HEAT_DATA_drp1.set_index([\"group_with_id\"], inplace = True,\n",
    "                            append = True, drop = False)\n",
    "CLEAN_dfheatmapREAL_drp = HEAT_DATA_drp1.groupby(level=1).mean()\n",
    "\n",
    "CLEAN_dfheatmap_final_drp = CLEAN_dfheatmapREAL_drp.drop(columns=['Row', 'Plane', 'Timepoint', 'Number of Analyzed Fields', 'Height [µm]',\n",
    "                            'Time [s]', 'Column', \"Cell ID\"])\n",
    "CLEAN_dfheatmap_final_drp.fillna(0, inplace=True)\n",
    "CLEAN_dfheatmap_final_NORMAL_drp = CLEAN_dfheatmap_final_drp.copy()\n",
    "CLEAN_dfheatmap_final_NORMAL_drp=(CLEAN_dfheatmap_final_NORMAL_drp-CLEAN_dfheatmap_final_NORMAL_drp.mean())/CLEAN_dfheatmap_final_NORMAL_drp.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cde5c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = 'mito_drp1_cor.csv'\n",
    "CLEAN_dfheatmap_final_NORMAL_drp.to_csv(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c6b767",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_drp_f = frame_drp_f.drop(columns=['Row', 'Plane', 'Timepoint', 'Number of Analyzed Fields', 'Height [µm]',\n",
    "                            'Time [s]', 'Column', 'Compound', \"Cell Type\", \"Cell ID\"])\n",
    "frame_drp_f = frame_drp_f.drop(columns=['modified_spots_chanel_3 - Total Spot Area - Mean per Well', 'modified_spots_chanel_3 - Relative Spot Intensity - Mean per Well',\n",
    "                                        'modified_spots_chanel_3 - Number of Spots per Area of modified_spots_chanel_3 - Mean per Well', 'modified_ir_chanel_3_at - modified_ir_chanel_3_at Area [µm²] - Mean per Well', \n",
    "                                        'all_cells - chanel_3 Gabor Max 2 px w2 - Mean per Well', 'all_cells - chanel_3 SER Spot 1 px - Mean per Well',\n",
    "                                        'all_cells - chanel_3 SER Hole 1 px - Mean per Well', 'all_cells - chanel_3 SER Edge 1 px - Mean per Well', \"all_cells - chanel_3 SER Ridge 1 px - Mean per Well\",\n",
    "                                        \"all_cells - chanel_3 SER Valley 1 px - Mean per Well\", \"all_cells - chanel_3_Intensity Mean - Mean per Well\",\n",
    "                                       \"all_cells - chanel_3_Intensity Sum - Sum per Well\", \"all_cells - chanel_2 Area [µm²] - Mean per Well\",\n",
    "                                       \"all_cells - chanel_1 Area [µm²] - Mean per Well\", \"all_cells - chanel_1 Roundness - Mean per Well\",\n",
    "                                       \"all_cells - chanel_1 Ratio Width to Length - Mean per Well\", \"all_cells - chanel_3 Threshold Compactness 30%  - Mean per Well\",\n",
    "                                       \"all_cells - chanel_3 Threshold Compactness 40%  - Mean per Well\", \"all_cells - chanel_3 Threshold Compactness 50%  - Mean per Well\",\n",
    "                                       \"all_cells - chanel_3 Threshold Compactness 60%  - Mean per Well\", \"all_cells - chanel_3 Radial Mean  - Mean per Well\",\n",
    "                                       \"all_cells - chanel_3 Radial Relative Deviation  - Mean per Well\", \"all_cells - chanel_3 Profile 1/5  - Mean per Well\",\n",
    "                                       \"all_cells - chanel_3 Profile 2/5  - Mean per Well\", \"all_cells - chanel_3 Profile 3/5  - Mean per Well\", \"all_cells - chanel_3 Profile 4/5  - Mean per Well\", \"all_cells - chanel_3 Profile 5/5  - Mean per Well\",\n",
    "                                       \"spots_chanel_3_final - Relative Spot Intensity - Mean per Well\", \"spots_chanel_3_final - Corrected Spot Intensity - Mean per Well\", \"spots_chanel_3_final - Uncorrected Spot Peak Intensity - Mean per Well\", \n",
    "                                       \"spots_chanel_3_final - Spot Contrast - Mean per Well\", \"spots_chanel_3_final - Spot Background Intensity - Mean per Well\", \"spots_chanel_3_final - Spot Area [px²] - Mean per Well\", \"spots_chanel_3_final - Region Intensity - Mean per Well\",\n",
    "                                       \"spots_chanel_3_final - Spot to Region Intensity - Mean per Well\", \"spots_chanel_3_final - Intensity_Spot chanel_3_final Mean - Mean per Well\", \"spots_chanel_3_final - spots_chanel_3_final Area [µm²] - Mean per Well\", \n",
    "                                       \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 30%  - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 40%  - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 50%  - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 60%  - Mean per Well\", \n",
    "                                        \"spots_chanel_3_final - spots_final_chanel_3 Radial Mean  - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Radial Relative Deviation  - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Profile 1/2  - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Profile 2/2  - Mean per Well\",\n",
    "                                       \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 30% SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 40% SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 50% SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 60% SER-Spot - Mean per Well\",\n",
    "                                       \"spots_chanel_3_final - spots_final_chanel_3 Radial Mean SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Radial Relative Deviation SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Radial Mean Ratio SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Profile 1/2 SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Profile 2/2 SER-Spot - Mean per Well\", \n",
    "                                       \"ir_chanel_3_total - ir_chanel_3_total Area [µm²] - Sum per Well\", \"total_ir_chanel_3_normalized\", \"modified_spots_chanel_3 - Number of Spots - Mean per Well\"])\n",
    "frame_drp_f = frame_drp_f.rename(columns={\"Severity\":\"group\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ecbcac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "##sum data\n",
    "frame_drp_f = frame_drp_f.dropna()\n",
    "summary_df = summarize_dataframe(frame_drp_f,'group')\n",
    "file2 = 'summary_mito_drp.csv'\n",
    "summary_df.to_csv(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "24b31318",
   "metadata": {},
   "outputs": [],
   "source": [
    "file3 = 'mito_drp1_combined.csv'\n",
    "frame_drp_f.to_csv(file3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfa104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##PCA\n",
    "PCA_DATA = frame_drp_f.copy()\n",
    "PCA_DATA.fillna(0, inplace=True)\n",
    "features2 = PCA_DATA.columns[:54]  \n",
    "x2 = PCA_DATA.loc[:, features2].values\n",
    "y2 = PCA_DATA.loc[:,['group']].values\n",
    "x2 = StandardScaler().fit_transform(x2)\n",
    "pd.DataFrame(data = x2, columns = features2).head()\n",
    "pca2 = PCA(n_components=2)\n",
    "principalComponents2 = pca2.fit_transform(x2)\n",
    "PCA_DATA2_COMP = pd.DataFrame(data = principalComponents2\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "importances2 = pd.DataFrame(data = abs(pca2.components_).transpose(), columns = ['PC1', 'PC2'])\n",
    "importances2['Feature'] = features2\n",
    "display(importances2.sort_values('PC1', ascending = False).reset_index(drop = True))\n",
    "imp2 = importances2.sort_values('PC2', ascending = False)[0:30]\n",
    "\n",
    "ax2 = sns.barplot(x = 'PC2', y = 'Feature', data = imp2)\n",
    "fig = ax2.get_figure()\n",
    "fig.set_size_inches(4, 8)\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation = 90)  \n",
    "#plt.savefig(path + '//' + 'drp1_PC2.pdf', dpi = 600)\n",
    "plt.show()\n",
    "    \n",
    "imp4 = importances2.sort_values('PC1', ascending = False)[0:30]\n",
    "ax2 = sns.barplot(x = 'PC1', y = 'Feature', data = imp4)\n",
    "    # Put the legend out of the figure\n",
    "    #plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "fig = ax2.get_figure()\n",
    "fig.set_size_inches(4, 8)\n",
    "ax2.tick_params(axis='x', labelsize=6)\n",
    "ax2.tick_params(axis='y', labelsize=6)\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation = 90)  \n",
    "#plt.savefig(path + '//' 'drp1_PC1.pdf', dpi = 700)\n",
    "plt.show()\n",
    "    \n",
    "PCA_DATA2_FINAL = pd.concat([PCA_DATA2_COMP, PCA_DATA[['group']]], axis = 1)\n",
    "PCA_FIG2 = plt.figure(figsize = (8,8))\n",
    "ax2 = PCA_FIG2.add_subplot(1,1,1) \n",
    "ax2.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax2.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax2.set_title('2 Component PCA', fontsize = 20)\n",
    "ax2.tick_params(axis='x', labelsize=6)\n",
    "ax2.tick_params(axis='y', labelsize=6)\n",
    "for tick in ax2.get_xticklabels():\n",
    "    tick.set_fontname(\"Arial\")\n",
    "for tick in ax2.get_yticklabels():\n",
    "    tick.set_fontname(\"Arial\")\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "targets2 = ['HC', 'S']\n",
    "colors2 = ['b', 'r']\n",
    "for target, color in zip(targets2,colors2):\n",
    "    indicesToKeep = PCA_DATA2_FINAL['group'] == target\n",
    "    ax2.scatter(PCA_DATA2_FINAL.loc[indicesToKeep, 'principal component 1']\n",
    "               , PCA_DATA2_FINAL.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "    ax2.legend(targets2)\n",
    "    ax2.grid()\n",
    "\n",
    "print(pca2.explained_variance_ratio_)\n",
    "plt.savefig(path + '//' + 'drp1_PCA2.pdf', dpi = 300)\n",
    "plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce7fa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA\n",
    "PCA_DATA_CLEAN = frame_drp_f.copy()\n",
    "\n",
    "x = PCA_DATA_CLEAN.loc[:, features2].values\n",
    "y = PCA_DATA_CLEAN.loc[:,['group']].values\n",
    "y = np.array([int('HC' == y_i[0][:2]) for y_i in y])\n",
    "\n",
    "y[0]=2\n",
    "x = StandardScaler().fit_transform(x)\n",
    "\n",
    "lda = LDA(n_components=2)\n",
    "lda_x = np.array(lda.fit(x, y).transform(x))\n",
    "\n",
    "\n",
    "importances = pd.DataFrame(data = abs(lda.scalings_), columns = ['PC1', 'PC2'])\n",
    "importances['Feature'] = features2\n",
    "display(importances.sort_values('PC1', ascending = False).reset_index(drop = True))\n",
    "imp = importances.sort_values('PC2', ascending = False)[0:30]\n",
    "ax1 = sns.barplot(x = 'PC2', y = 'Feature', data = imp)\n",
    "    \n",
    "fig = ax1.get_figure()\n",
    "fig.set_size_inches(4, 8)\n",
    "plt.rc('ytick', labelsize=10)\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), rotation = 90)  \n",
    "#plt.savefig(path + '\\\\' + 'LDA1importancefeat1.pdf', dpi=600)\n",
    "plt.show()\n",
    "imp2 = importances.sort_values('PC1', ascending = False)[0:30]\n",
    "ax2 = sns.barplot(x = 'PC1', y = 'Feature', data = imp2)\n",
    "fig = ax2.get_figure()\n",
    "fig.set_size_inches(4, 8)\n",
    "plt.rc('ytick', labelsize=10)\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation = 90) \n",
    "#plt.savefig(path + '\\\\' + 'LDA1importancefeat2.pdf', dpi=600)\n",
    "plt.show()\n",
    "\n",
    "font = {'family' : 'Arial',\n",
    "        'size'   : 22}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "scale=6\n",
    "target_names= ['S', 'HC']\n",
    "plt.figure()\n",
    "plt.figure(figsize = (8,8))\n",
    "for c, i, target_name in zip(\"rb\", [0, 1], target_names):\n",
    "    plt.scatter(lda_x[y == i,0] , lda_x[y == i,1] , c=c, label=target_name)\n",
    "    plt.legend(target_names*scale,fontsize=12)\n",
    "#     plt.title('LDA of dataset')\n",
    "    plt.xlabel('LD1', fontsize = 20, family = 'Arial')\n",
    "    plt.ylabel('LD2', fontsize = 20, family = 'Arial')\n",
    "    plt.yticks(family = 'Arial', size = 10)\n",
    "    plt.xticks(family = 'Arial', size= 10)\n",
    "print(lda.explained_variance_ratio_)            \n",
    "plt.savefig(path + '\\\\' + 'drp-LDA.pdf', dpi=600 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed41435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAT1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de18af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob('noam_may_analysis_fold1/VAT1/*.csv')\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    li.append(df)\n",
    "\n",
    "vat1_df = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b3002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types =  vat1_df[\"Compound\"].values\n",
    "sns.histplot(cell_types)\n",
    "plt.show()\n",
    "print(f'Total number of cell types {len(cell_types)}')\n",
    "vat1_df = vat1_df.loc[cell_types != 'mdivi1 25uM']\n",
    "sns.histplot(vat1_df[\"Compound\"].values)\n",
    "plt.show()\n",
    "print(f'Total number of cells {len(vat1_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4de7ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h = vat1_df[(vat1_df[\"Severity\"] == 'HC')] \n",
    "df_s = vat1_df[(vat1_df[\"Severity\"] == 'S')]\n",
    "frame_vat = (df_h, df_s)\n",
    "frame_vat_f = pd.concat(frame_vat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a8d8a900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MiguelW12\\AppData\\Local\\Temp\\ipykernel_9812\\2454812790.py:5: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  CLEAN_dfheatmapREAL_vat1 = HEAT_DATA_vat1.groupby(level=1).mean()\n"
     ]
    }
   ],
   "source": [
    "HEAT_DATA_vat1 = frame_vat_f.copy()\n",
    "HEAT_DATA_vat1[\"group_with_id\"] = HEAT_DATA_vat1[\"Cell ID\"].astype(str) + HEAT_DATA_vat1[\"Cell Type\"].astype(str) \n",
    "HEAT_DATA_vat1.set_index([\"group_with_id\"], inplace = True,\n",
    "                            append = True, drop = False)\n",
    "CLEAN_dfheatmapREAL_vat1 = HEAT_DATA_vat1.groupby(level=1).mean()\n",
    "\n",
    "CLEAN_dfheatmap_final_vat1 = CLEAN_dfheatmapREAL_vat1.drop(columns=['Row', 'Plane', 'Timepoint', 'Number of Analyzed Fields', 'Height [µm]',\n",
    "                            'Time [s]', 'Column', \"Cell ID\"])\n",
    "CLEAN_dfheatmap_final_vat1.fillna(0, inplace=True)\n",
    "CLEAN_dfheatmap_final_NORMAL_vat1 = CLEAN_dfheatmap_final_vat1.copy()\n",
    "CLEAN_dfheatmap_final_NORMAL_vat1=(CLEAN_dfheatmap_final_NORMAL_vat1-CLEAN_dfheatmap_final_NORMAL_vat1.mean())/CLEAN_dfheatmap_final_NORMAL_vat1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "70b93433",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = 'mito_vat1_cor.csv'\n",
    "CLEAN_dfheatmap_final_NORMAL_vat1.to_csv(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4732c812",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_vat_f = frame_vat_f.drop(columns=['Row', 'Plane', 'Timepoint', 'Number of Analyzed Fields', 'Height [µm]',\n",
    "                            'Time [s]', 'Column', 'Compound', \"Cell Type\", \"Cell ID\"])\n",
    "frame_vat_f = frame_vat_f.drop(columns=['modified_spots_chanel_3 - Total Spot Area - Mean per Well', 'modified_spots_chanel_3 - Relative Spot Intensity - Mean per Well',\n",
    "                                        'modified_spots_chanel_3 - Number of Spots per Area of modified_spots_chanel_3 - Mean per Well', 'modified_ir_chanel_3_at - modified_ir_chanel_3_at Area [µm²] - Mean per Well', \n",
    "                                        'all_cells - chanel_3 Gabor Max 2 px w2 - Mean per Well', 'all_cells - chanel_3 SER Spot 1 px - Mean per Well',\n",
    "                                        'all_cells - chanel_3 SER Hole 1 px - Mean per Well', 'all_cells - chanel_3 SER Edge 1 px - Mean per Well', \"all_cells - chanel_3 SER Ridge 1 px - Mean per Well\",\n",
    "                                        \"all_cells - chanel_3 SER Valley 1 px - Mean per Well\", \"all_cells - chanel_3_Intensity Mean - Mean per Well\",\n",
    "                                       \"all_cells - chanel_3_Intensity Sum - Sum per Well\", \"all_cells - chanel_2 Area [µm²] - Mean per Well\",\n",
    "                                       \"all_cells - chanel_1 Area [µm²] - Mean per Well\", \"all_cells - chanel_1 Roundness - Mean per Well\",\n",
    "                                       \"all_cells - chanel_1 Ratio Width to Length - Mean per Well\", \"all_cells - chanel_3 Threshold Compactness 30%  - Mean per Well\",\n",
    "                                       \"all_cells - chanel_3 Threshold Compactness 40%  - Mean per Well\", \"all_cells - chanel_3 Threshold Compactness 50%  - Mean per Well\",\n",
    "                                       \"all_cells - chanel_3 Threshold Compactness 60%  - Mean per Well\", \"all_cells - chanel_3 Radial Mean  - Mean per Well\",\n",
    "                                       \"all_cells - chanel_3 Radial Relative Deviation  - Mean per Well\", \"all_cells - chanel_3 Profile 1/5  - Mean per Well\",\n",
    "                                       \"all_cells - chanel_3 Profile 2/5  - Mean per Well\", \"all_cells - chanel_3 Profile 3/5  - Mean per Well\", \"all_cells - chanel_3 Profile 4/5  - Mean per Well\", \"all_cells - chanel_3 Profile 5/5  - Mean per Well\",\n",
    "                                       \"spots_chanel_3_final - Relative Spot Intensity - Mean per Well\", \"spots_chanel_3_final - Corrected Spot Intensity - Mean per Well\", \"spots_chanel_3_final - Uncorrected Spot Peak Intensity - Mean per Well\", \n",
    "                                       \"spots_chanel_3_final - Spot Contrast - Mean per Well\", \"spots_chanel_3_final - Spot Background Intensity - Mean per Well\", \"spots_chanel_3_final - Spot Area [px²] - Mean per Well\", \"spots_chanel_3_final - Region Intensity - Mean per Well\",\n",
    "                                       \"spots_chanel_3_final - Spot to Region Intensity - Mean per Well\", \"spots_chanel_3_final - Intensity_Spot chanel_3_final Mean - Mean per Well\", \"spots_chanel_3_final - spots_chanel_3_final Area [µm²] - Mean per Well\", \n",
    "                                       \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 30%  - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 40%  - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 50%  - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 60%  - Mean per Well\", \n",
    "                                        \"spots_chanel_3_final - spots_final_chanel_3 Radial Mean  - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Radial Relative Deviation  - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Profile 1/2  - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Profile 2/2  - Mean per Well\",\n",
    "                                       \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 30% SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 40% SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 50% SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 60% SER-Spot - Mean per Well\",\n",
    "                                       \"spots_chanel_3_final - spots_final_chanel_3 Radial Mean SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Radial Relative Deviation SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Radial Mean Ratio SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Profile 1/2 SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Profile 2/2 SER-Spot - Mean per Well\", \n",
    "                                       \"ir_chanel_3_total - ir_chanel_3_total Area [µm²] - Sum per Well\", \"total_ir_chanel_3_normalized\", \"modified_spots_chanel_3 - Number of Spots - Mean per Well\"])\n",
    "frame_vat_f = frame_vat_f.rename(columns={\"Severity\":\"group\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "805f889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_vat_f = frame_vat_f.dropna()\n",
    "summary_df = summarize_dataframe(frame_vat_f,'group')\n",
    "file1 = 'summary_mito_vat.csv'\n",
    "summary_df.to_csv(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e199faf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = 'mito_vat1_combined.csv'\n",
    "frame_vat_f.to_csv(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31c48c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_DATA = frame_vat_f.copy()\n",
    "PCA_DATA.fillna(0, inplace=True)\n",
    "features2 = PCA_DATA.columns[:54]  \n",
    "x2 = PCA_DATA.loc[:, features2].values\n",
    "y2 = PCA_DATA.loc[:,['group']].values\n",
    "x2 = StandardScaler().fit_transform(x2)\n",
    "pd.DataFrame(data = x2, columns = features2).head()\n",
    "pca2 = PCA(n_components=2)\n",
    "principalComponents2 = pca2.fit_transform(x2)\n",
    "PCA_DATA2_COMP = pd.DataFrame(data = principalComponents2\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "importances2 = pd.DataFrame(data = abs(pca2.components_).transpose(), columns = ['PC1', 'PC2'])\n",
    "importances2['Feature'] = features2\n",
    "display(importances2.sort_values('PC1', ascending = False).reset_index(drop = True))\n",
    "imp2 = importances2.sort_values('PC2', ascending = False)[0:30]\n",
    "\n",
    "ax2 = sns.barplot(x = 'PC2', y = 'Feature', data = imp2)\n",
    "fig = ax2.get_figure()\n",
    "fig.set_size_inches(4, 8)\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation = 90)  \n",
    "#plt.savefig(path + '//' + 'drp1_PC2.pdf', dpi = 600)\n",
    "plt.show()\n",
    "    \n",
    "imp4 = importances2.sort_values('PC1', ascending = False)[0:30]\n",
    "ax2 = sns.barplot(x = 'PC1', y = 'Feature', data = imp4)\n",
    "    # Put the legend out of the figure\n",
    "    #plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "fig = ax2.get_figure()\n",
    "fig.set_size_inches(4, 8)\n",
    "ax2.tick_params(axis='x', labelsize=6)\n",
    "ax2.tick_params(axis='y', labelsize=6)\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation = 90)  \n",
    "#plt.savefig(path + '//' 'drp1_PC1.pdf', dpi = 700)\n",
    "plt.show()\n",
    "    \n",
    "PCA_DATA2_FINAL = pd.concat([PCA_DATA2_COMP, PCA_DATA[['group']]], axis = 1)\n",
    "PCA_FIG2 = plt.figure(figsize = (8,8))\n",
    "ax2 = PCA_FIG2.add_subplot(1,1,1) \n",
    "ax2.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax2.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax2.set_title('2 Component PCA', fontsize = 20)\n",
    "ax2.tick_params(axis='x', labelsize=6)\n",
    "ax2.tick_params(axis='y', labelsize=6)\n",
    "for tick in ax2.get_xticklabels():\n",
    "    tick.set_fontname(\"Arial\")\n",
    "for tick in ax2.get_yticklabels():\n",
    "    tick.set_fontname(\"Arial\")\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "targets2 = ['HC', 'S']\n",
    "colors2 = ['b', 'r']\n",
    "for target, color in zip(targets2,colors2):\n",
    "    indicesToKeep = PCA_DATA2_FINAL['group'] == target\n",
    "    ax2.scatter(PCA_DATA2_FINAL.loc[indicesToKeep, 'principal component 1']\n",
    "               , PCA_DATA2_FINAL.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "    ax2.legend(targets2)\n",
    "    ax2.grid()\n",
    "\n",
    "    \n",
    "print(pca2.explained_variance_ratio_)\n",
    "plt.savefig(path + '//' + 'vat1_PCA2.pdf', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985df03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##LDA\n",
    "\n",
    "PCA_DATA_CLEAN = frame_vat_f.copy()\n",
    "\n",
    "x = PCA_DATA_CLEAN.loc[:, features2].values\n",
    "y = PCA_DATA_CLEAN.loc[:,['group']].values\n",
    "y = np.array([int('HC' == y_i[0][:2]) for y_i in y])\n",
    "\n",
    "y[0]=2\n",
    "x = StandardScaler().fit_transform(x)\n",
    "\n",
    "lda = LDA(n_components=2)\n",
    "lda_x = np.array(lda.fit(x, y).transform(x))\n",
    "\n",
    "\n",
    "importances = pd.DataFrame(data = abs(lda.scalings_), columns = ['PC1', 'PC2'])\n",
    "importances['Feature'] = features2\n",
    "display(importances.sort_values('PC1', ascending = False).reset_index(drop = True))\n",
    "imp = importances.sort_values('PC2', ascending = False)[0:30]\n",
    "ax1 = sns.barplot(x = 'PC2', y = 'Feature', data = imp)\n",
    "    \n",
    "fig = ax1.get_figure()\n",
    "fig.set_size_inches(4, 8)\n",
    "plt.rc('ytick', labelsize=10)\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), rotation = 90)  \n",
    "#plt.savefig(path + '\\\\' + 'LDA1importancefeat1.pdf', dpi=600)\n",
    "plt.show()\n",
    "imp2 = importances.sort_values('PC1', ascending = False)[0:30]\n",
    "ax2 = sns.barplot(x = 'PC1', y = 'Feature', data = imp2)\n",
    "fig = ax2.get_figure()\n",
    "fig.set_size_inches(4, 8)\n",
    "plt.rc('ytick', labelsize=10)\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation = 90) \n",
    "#plt.savefig(path + '\\\\' + 'LDA1importancefeat2.pdf', dpi=600)\n",
    "plt.show()\n",
    "\n",
    "font = {'family' : 'Arial',\n",
    "        'size'   : 22}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "scale=6\n",
    "target_names= ['S', 'HC']\n",
    "plt.figure()\n",
    "plt.figure(figsize = (8,8))\n",
    "for c, i, target_name in zip(\"rb\", [0, 1], target_names):\n",
    "    plt.scatter(lda_x[y == i,0] , lda_x[y == i,1] , c=c, label=target_name)\n",
    "    plt.legend(target_names*scale,fontsize=12)\n",
    "#     plt.title('LDA of dataset')\n",
    "    plt.xlabel('LD1', fontsize = 20, family = 'Arial')\n",
    "    plt.ylabel('LD2', fontsize = 20, family = 'Arial')\n",
    "    plt.yticks(family = 'Arial', size = 10)\n",
    "    plt.xticks(family = 'Arial', size= 10)\n",
    "print(lda.explained_variance_ratio_)            \n",
    "plt.savefig(path + '\\\\' + 'vat-LDA.pdf', dpi=600 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44e8295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MFN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e14753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob('noam_may_analysis_fold1/MFN1/*.csv')\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    li.append(df)\n",
    "\n",
    "mfn1_df = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffe9d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types =  mfn1_df[\"Compound\"].values\n",
    "sns.histplot(cell_types)\n",
    "plt.show()\n",
    "print(f'Total number of cell types {len(cell_types)}')\n",
    "mfn1_df = mfn1_df.loc[cell_types != 'mdivi1 25uM']\n",
    "sns.histplot(mfn1_df[\"Compound\"].values)\n",
    "plt.show()\n",
    "print(f'Total number of cells {len(mfn1_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaceb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h = mfn1_df[(mfn1_df[\"Severity\"] == 'HC')] \n",
    "df_s = mfn1_df[(mfn1_df[\"Severity\"] == 'S')]\n",
    "frame_mfn1 = (df_h, df_s)\n",
    "frame_mfn1_f = pd.concat(frame_mfn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "567a956b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MiguelW12\\AppData\\Local\\Temp\\ipykernel_9812\\1051816466.py:5: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  CLEAN_dfheatmapREAL_mfn1 = HEAT_DATA_mfn1.groupby(level=1).mean()\n"
     ]
    }
   ],
   "source": [
    "HEAT_DATA_mfn1 = frame_mfn1_f.copy()\n",
    "HEAT_DATA_mfn1[\"group_with_id\"] = HEAT_DATA_mfn1[\"Cell ID\"].astype(str) + HEAT_DATA_mfn1[\"Cell Type\"].astype(str) \n",
    "HEAT_DATA_mfn1.set_index([\"group_with_id\"], inplace = True,\n",
    "                            append = True, drop = False)\n",
    "CLEAN_dfheatmapREAL_mfn1 = HEAT_DATA_mfn1.groupby(level=1).mean()\n",
    "\n",
    "CLEAN_dfheatmap_final_mfn1 = CLEAN_dfheatmapREAL_mfn1.drop(columns=['Row', 'Plane', 'Timepoint', 'Number of Analyzed Fields', 'Height [µm]',\n",
    "                            'Time [s]', 'Column', \"Cell ID\"])\n",
    "CLEAN_dfheatmap_final_mfn1.fillna(0, inplace=True)\n",
    "CLEAN_dfheatmap_final_NORMAL_mfn1 = CLEAN_dfheatmap_final_mfn1.copy()\n",
    "CLEAN_dfheatmap_final_NORMAL_mfn1=(CLEAN_dfheatmap_final_NORMAL_mfn1-CLEAN_dfheatmap_final_NORMAL_mfn1.mean())/CLEAN_dfheatmap_final_NORMAL_mfn1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0abd2c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = 'mito_mfn1_cor.csv'\n",
    "CLEAN_dfheatmap_final_NORMAL_mfn1.to_csv(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9d44f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_mfn1_f = frame_mfn1_f.drop(columns=['Row', 'Plane', 'Timepoint', 'Number of Analyzed Fields', 'Height [µm]',\n",
    "                            'Time [s]', 'Column', 'Compound', \"Cell Type\", \"Cell ID\"])\n",
    "frame_mfn1_f = frame_mfn1_f.drop(columns=['modified_spots_chanel_3 - Total Spot Area - Mean per Well', 'modified_spots_chanel_3 - Relative Spot Intensity - Mean per Well',\n",
    "                                        'modified_spots_chanel_3 - Number of Spots per Area of modified_spots_chanel_3 - Mean per Well', 'modified_ir_chanel_3_at - modified_ir_chanel_3_at Area [µm²] - Mean per Well', \n",
    "                                        'all_cells - chanel_3 Gabor Max 2 px w2 - Mean per Well', 'all_cells - chanel_3 SER Spot 1 px - Mean per Well',\n",
    "                                        'all_cells - chanel_3 SER Hole 1 px - Mean per Well', 'all_cells - chanel_3 SER Edge 1 px - Mean per Well', \"all_cells - chanel_3 SER Ridge 1 px - Mean per Well\",\n",
    "                                        \"all_cells - chanel_3 SER Valley 1 px - Mean per Well\", \"all_cells - chanel_3_Intensity Mean - Mean per Well\",\n",
    "                                       \"all_cells - chanel_3_Intensity Sum - Sum per Well\", \"all_cells - chanel_2 Area [µm²] - Mean per Well\",\n",
    "                                       \"all_cells - chanel_1 Area [µm²] - Mean per Well\", \"all_cells - chanel_1 Roundness - Mean per Well\",\n",
    "                                       \"all_cells - chanel_1 Ratio Width to Length - Mean per Well\", \"all_cells - chanel_3 Threshold Compactness 30%  - Mean per Well\",\n",
    "                                       \"all_cells - chanel_3 Threshold Compactness 40%  - Mean per Well\", \"all_cells - chanel_3 Threshold Compactness 50%  - Mean per Well\",\n",
    "                                       \"all_cells - chanel_3 Threshold Compactness 60%  - Mean per Well\", \"all_cells - chanel_3 Radial Mean  - Mean per Well\",\n",
    "                                       \"all_cells - chanel_3 Radial Relative Deviation  - Mean per Well\", \"all_cells - chanel_3 Profile 1/5  - Mean per Well\",\n",
    "                                       \"all_cells - chanel_3 Profile 2/5  - Mean per Well\", \"all_cells - chanel_3 Profile 3/5  - Mean per Well\", \"all_cells - chanel_3 Profile 4/5  - Mean per Well\", \"all_cells - chanel_3 Profile 5/5  - Mean per Well\",\n",
    "                                       \"spots_chanel_3_final - Relative Spot Intensity - Mean per Well\", \"spots_chanel_3_final - Corrected Spot Intensity - Mean per Well\", \"spots_chanel_3_final - Uncorrected Spot Peak Intensity - Mean per Well\", \n",
    "                                       \"spots_chanel_3_final - Spot Contrast - Mean per Well\", \"spots_chanel_3_final - Spot Background Intensity - Mean per Well\", \"spots_chanel_3_final - Spot Area [px²] - Mean per Well\", \"spots_chanel_3_final - Region Intensity - Mean per Well\",\n",
    "                                       \"spots_chanel_3_final - Spot to Region Intensity - Mean per Well\", \"spots_chanel_3_final - Intensity_Spot chanel_3_final Mean - Mean per Well\", \"spots_chanel_3_final - spots_chanel_3_final Area [µm²] - Mean per Well\", \n",
    "                                       \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 30%  - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 40%  - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 50%  - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 60%  - Mean per Well\", \n",
    "                                        \"spots_chanel_3_final - spots_final_chanel_3 Radial Mean  - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Radial Relative Deviation  - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Profile 1/2  - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Profile 2/2  - Mean per Well\",\n",
    "                                       \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 30% SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 40% SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 50% SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 60% SER-Spot - Mean per Well\",\n",
    "                                       \"spots_chanel_3_final - spots_final_chanel_3 Radial Mean SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Radial Relative Deviation SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Radial Mean Ratio SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Profile 1/2 SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Profile 2/2 SER-Spot - Mean per Well\", \n",
    "                                       \"ir_chanel_3_total - ir_chanel_3_total Area [µm²] - Sum per Well\", \"total_ir_chanel_3_normalized\", \"modified_spots_chanel_3 - Number of Spots - Mean per Well\"])\n",
    "frame_mfn1_f = frame_mfn1_f.rename(columns={\"Severity\":\"group\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ebdb3224",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_mfn1_f = frame_mfn1_f.dropna()\n",
    "summary_df = summarize_dataframe(frame_mfn1_f,'group')\n",
    "file1 = 'summary_mito_mfn1.csv'\n",
    "summary_df.to_csv(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5ea5fa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = 'mito_mfn1_combined.csv'\n",
    "frame_mfn1_f.to_csv(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3245ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "PCA_DATA = frame_mfn1_f.copy()\n",
    "PCA_DATA.fillna(0, inplace=True)\n",
    "features2 = PCA_DATA.columns[:54]  \n",
    "x2 = PCA_DATA.loc[:, features2].values\n",
    "y2 = PCA_DATA.loc[:,['group']].values\n",
    "x2 = StandardScaler().fit_transform(x2)\n",
    "pd.DataFrame(data = x2, columns = features2).head()\n",
    "pca2 = PCA(n_components=2)\n",
    "principalComponents2 = pca2.fit_transform(x2)\n",
    "PCA_DATA2_COMP = pd.DataFrame(data = principalComponents2\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "importances2 = pd.DataFrame(data = abs(pca2.components_).transpose(), columns = ['PC1', 'PC2'])\n",
    "importances2['Feature'] = features2\n",
    "display(importances2.sort_values('PC1', ascending = False).reset_index(drop = True))\n",
    "imp2 = importances2.sort_values('PC2', ascending = False)[0:30]\n",
    "\n",
    "ax2 = sns.barplot(x = 'PC2', y = 'Feature', data = imp2)\n",
    "fig = ax2.get_figure()\n",
    "fig.set_size_inches(4, 8)\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation = 90)  \n",
    "#plt.savefig(path + '//' + 'drp1_PC2.pdf', dpi = 600)\n",
    "plt.show()\n",
    "    \n",
    "imp4 = importances2.sort_values('PC1', ascending = False)[0:30]\n",
    "ax2 = sns.barplot(x = 'PC1', y = 'Feature', data = imp4)\n",
    "    # Put the legend out of the figure\n",
    "    #plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "fig = ax2.get_figure()\n",
    "fig.set_size_inches(4, 8)\n",
    "ax2.tick_params(axis='x', labelsize=6)\n",
    "ax2.tick_params(axis='y', labelsize=6)\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation = 90)  \n",
    "#plt.savefig(path + '//' 'drp1_PC1.pdf', dpi = 700)\n",
    "plt.show()\n",
    "    \n",
    "PCA_DATA2_FINAL = pd.concat([PCA_DATA2_COMP, PCA_DATA[['group']]], axis = 1)\n",
    "PCA_FIG2 = plt.figure(figsize = (8,8))\n",
    "ax2 = PCA_FIG2.add_subplot(1,1,1) \n",
    "ax2.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax2.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax2.set_title('2 Component PCA', fontsize = 20)\n",
    "ax2.tick_params(axis='x', labelsize=6)\n",
    "ax2.tick_params(axis='y', labelsize=6)\n",
    "for tick in ax2.get_xticklabels():\n",
    "    tick.set_fontname(\"Arial\")\n",
    "for tick in ax2.get_yticklabels():\n",
    "    tick.set_fontname(\"Arial\")\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "targets2 = ['HC', 'S']\n",
    "colors2 = ['b', 'r']\n",
    "for target, color in zip(targets2,colors2):\n",
    "    indicesToKeep = PCA_DATA2_FINAL['group'] == target\n",
    "    ax2.scatter(PCA_DATA2_FINAL.loc[indicesToKeep, 'principal component 1']\n",
    "               , PCA_DATA2_FINAL.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "    ax2.legend(targets2)\n",
    "    ax2.grid()\n",
    "\n",
    "    \n",
    "print(pca2.explained_variance_ratio_)\n",
    "plt.savefig(path + '//' + 'mfn1_PCA2.pdf', dpi = 300)\n",
    "plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8ada14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA\n",
    "PCA_DATA_CLEAN = frame_mfn1_f.copy()\n",
    "\n",
    "x = PCA_DATA_CLEAN.loc[:, features2].values\n",
    "y = PCA_DATA_CLEAN.loc[:,['group']].values\n",
    "y = np.array([int('HC' == y_i[0][:2]) for y_i in y])\n",
    "\n",
    "y[0]=2\n",
    "x = StandardScaler().fit_transform(x)\n",
    "\n",
    "lda = LDA(n_components=2)\n",
    "lda_x = np.array(lda.fit(x, y).transform(x))\n",
    "\n",
    "\n",
    "importances = pd.DataFrame(data = abs(lda.scalings_), columns = ['PC1', 'PC2'])\n",
    "importances['Feature'] = features2\n",
    "display(importances.sort_values('PC1', ascending = False).reset_index(drop = True))\n",
    "imp = importances.sort_values('PC2', ascending = False)[0:30]\n",
    "ax1 = sns.barplot(x = 'PC2', y = 'Feature', data = imp)\n",
    "    \n",
    "fig = ax1.get_figure()\n",
    "fig.set_size_inches(4, 8)\n",
    "plt.rc('ytick', labelsize=10)\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), rotation = 90)  \n",
    "#plt.savefig(path + '\\\\' + 'LDA1importancefeat1.pdf', dpi=600)\n",
    "plt.show()\n",
    "imp2 = importances.sort_values('PC1', ascending = False)[0:30]\n",
    "ax2 = sns.barplot(x = 'PC1', y = 'Feature', data = imp2)\n",
    "fig = ax2.get_figure()\n",
    "fig.set_size_inches(4, 8)\n",
    "plt.rc('ytick', labelsize=10)\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation = 90) \n",
    "#plt.savefig(path + '\\\\' + 'LDA1importancefeat2.pdf', dpi=600)\n",
    "plt.show()\n",
    "\n",
    "font = {'family' : 'Arial',\n",
    "        'size'   : 22}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "scale=6\n",
    "target_names= ['S', 'HC']\n",
    "plt.figure()\n",
    "plt.figure(figsize = (8,8))\n",
    "for c, i, target_name in zip(\"rb\", [0, 1], target_names):\n",
    "    plt.scatter(lda_x[y == i,0] , lda_x[y == i,1] , c=c, label=target_name)\n",
    "    plt.legend(target_names*scale,fontsize=12)\n",
    "#     plt.title('LDA of dataset')\n",
    "    plt.xlabel('LD1', fontsize = 20, family = 'Arial')\n",
    "    plt.ylabel('LD2', fontsize = 20, family = 'Arial')\n",
    "    plt.yticks(family = 'Arial', size = 10)\n",
    "    plt.xticks(family = 'Arial', size= 10)\n",
    "print(lda.explained_variance_ratio_)            \n",
    "plt.savefig(path + '\\\\' + 'mfn1-LDA.pdf', dpi=600 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc59a2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MFN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32a5268",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob('noam_may_analysis_fold1/MFN2/*.csv')\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    li.append(df)\n",
    "\n",
    "mfn2_df = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b131b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types =  mfn2_df[\"Compound\"].values\n",
    "sns.histplot(cell_types)\n",
    "plt.show()\n",
    "print(f'Total number of cell types {len(cell_types)}')\n",
    "mfn2_df = mfn2_df.loc[cell_types != 'mdivi1 25uM']\n",
    "sns.histplot(mfn2_df[\"Compound\"].values)\n",
    "plt.show()\n",
    "print(f'Total number of cells {len(mfn2_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adfa2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h = mfn2_df[(mfn2_df[\"Severity\"] == 'HC')] \n",
    "df_s = mfn2_df[(mfn2_df[\"Severity\"] == 'S')]\n",
    "frame_mfn2 = (df_h, df_s)\n",
    "frame_mfn2_f = pd.concat(frame_mfn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cc74e4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MiguelW12\\AppData\\Local\\Temp\\ipykernel_9812\\3976612670.py:5: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  CLEAN_dfheatmapREAL_mfn2 = HEAT_DATA_mfn2.groupby(level=1).mean()\n"
     ]
    }
   ],
   "source": [
    "HEAT_DATA_mfn2 = frame_mfn2_f.copy()\n",
    "HEAT_DATA_mfn2[\"group_with_id\"] = HEAT_DATA_mfn2[\"Cell ID\"].astype(str) + HEAT_DATA_mfn2[\"Cell Type\"].astype(str) \n",
    "HEAT_DATA_mfn2.set_index([\"group_with_id\"], inplace = True,\n",
    "                            append = True, drop = False)\n",
    "CLEAN_dfheatmapREAL_mfn2 = HEAT_DATA_mfn2.groupby(level=1).mean()\n",
    "\n",
    "CLEAN_dfheatmap_final_mfn2 = CLEAN_dfheatmapREAL_mfn2.drop(columns=['Row', 'Plane', 'Timepoint', 'Number of Analyzed Fields', 'Height [µm]',\n",
    "                            'Time [s]', 'Column', \"Cell ID\"])\n",
    "CLEAN_dfheatmap_final_mfn2.fillna(0, inplace=True)\n",
    "CLEAN_dfheatmap_final_NORMAL_mfn2 = CLEAN_dfheatmap_final_mfn2.copy()\n",
    "CLEAN_dfheatmap_final_NORMAL_mfn2=(CLEAN_dfheatmap_final_NORMAL_mfn2-CLEAN_dfheatmap_final_NORMAL_mfn2.mean())/CLEAN_dfheatmap_final_NORMAL_mfn2.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "229c5558",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = 'mito_mfn2_cor.csv'\n",
    "CLEAN_dfheatmap_final_NORMAL_mfn2.to_csv(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5d7cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_mfn2_f = frame_mfn2_f.drop(columns=['Row', 'Plane', 'Timepoint', 'Number of Analyzed Fields', 'Height [µm]',\n",
    "                            'Time [s]', 'Column', 'Compound', \"Cell Type\", \"Cell ID\"])\n",
    "frame_mfn2_f = frame_mfn2_f.drop(columns=['modified_spots_chanel_3 - Total Spot Area - Mean per Well', 'modified_spots_chanel_3 - Relative Spot Intensity - Mean per Well',\n",
    "                                        'modified_spots_chanel_3 - Number of Spots per Area of modified_spots_chanel_3 - Mean per Well', 'modified_ir_chanel_3_at - modified_ir_chanel_3_at Area [µm²] - Mean per Well', \n",
    "                                        'all_cells - chanel_3 Gabor Max 2 px w2 - Mean per Well', 'all_cells - chanel_3 SER Spot 1 px - Mean per Well',\n",
    "                                        'all_cells - chanel_3 SER Hole 1 px - Mean per Well', 'all_cells - chanel_3 SER Edge 1 px - Mean per Well', \"all_cells - chanel_3 SER Ridge 1 px - Mean per Well\",\n",
    "                                        \"all_cells - chanel_3 SER Valley 1 px - Mean per Well\", \"all_cells - chanel_3_Intensity Mean - Mean per Well\",\n",
    "                                       \"all_cells - chanel_3_Intensity Sum - Sum per Well\", \"all_cells - chanel_2 Area [µm²] - Mean per Well\",\n",
    "                                       \"all_cells - chanel_1 Area [µm²] - Mean per Well\", \"all_cells - chanel_1 Roundness - Mean per Well\",\n",
    "                                       \"all_cells - chanel_1 Ratio Width to Length - Mean per Well\", \"all_cells - chanel_3 Threshold Compactness 30%  - Mean per Well\",\n",
    "                                       \"all_cells - chanel_3 Threshold Compactness 40%  - Mean per Well\", \"all_cells - chanel_3 Threshold Compactness 50%  - Mean per Well\",\n",
    "                                       \"all_cells - chanel_3 Threshold Compactness 60%  - Mean per Well\", \"all_cells - chanel_3 Radial Mean  - Mean per Well\",\n",
    "                                       \"all_cells - chanel_3 Radial Relative Deviation  - Mean per Well\", \"all_cells - chanel_3 Profile 1/5  - Mean per Well\",\n",
    "                                       \"all_cells - chanel_3 Profile 2/5  - Mean per Well\", \"all_cells - chanel_3 Profile 3/5  - Mean per Well\", \"all_cells - chanel_3 Profile 4/5  - Mean per Well\", \"all_cells - chanel_3 Profile 5/5  - Mean per Well\",\n",
    "                                       \"spots_chanel_3_final - Relative Spot Intensity - Mean per Well\", \"spots_chanel_3_final - Corrected Spot Intensity - Mean per Well\", \"spots_chanel_3_final - Uncorrected Spot Peak Intensity - Mean per Well\", \n",
    "                                       \"spots_chanel_3_final - Spot Contrast - Mean per Well\", \"spots_chanel_3_final - Spot Background Intensity - Mean per Well\", \"spots_chanel_3_final - Spot Area [px²] - Mean per Well\", \"spots_chanel_3_final - Region Intensity - Mean per Well\",\n",
    "                                       \"spots_chanel_3_final - Spot to Region Intensity - Mean per Well\", \"spots_chanel_3_final - Intensity_Spot chanel_3_final Mean - Mean per Well\", \"spots_chanel_3_final - spots_chanel_3_final Area [µm²] - Mean per Well\", \n",
    "                                       \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 30%  - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 40%  - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 50%  - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 60%  - Mean per Well\", \n",
    "                                        \"spots_chanel_3_final - spots_final_chanel_3 Radial Mean  - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Radial Relative Deviation  - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Profile 1/2  - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Profile 2/2  - Mean per Well\",\n",
    "                                       \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 30% SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 40% SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 50% SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Threshold Compactness 60% SER-Spot - Mean per Well\",\n",
    "                                       \"spots_chanel_3_final - spots_final_chanel_3 Radial Mean SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Radial Relative Deviation SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Radial Mean Ratio SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Profile 1/2 SER-Spot - Mean per Well\", \"spots_chanel_3_final - spots_final_chanel_3 Profile 2/2 SER-Spot - Mean per Well\", \n",
    "                                       \"ir_chanel_3_total - ir_chanel_3_total Area [µm²] - Sum per Well\", \"total_ir_chanel_3_normalized\", \"modified_spots_chanel_3 - Number of Spots - Mean per Well\"])\n",
    "frame_mfn2_f = frame_mfn2_f.rename(columns={\"Severity\":\"group\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e1c8d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_mfn2_f = frame_mfn2_f.dropna()\n",
    "summary_df = summarize_dataframe(frame_mfn2_f,'group')\n",
    "file1 = 'summary_mito_mfn2.csv'\n",
    "summary_df.to_csv(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6aba2ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = 'mito_mfn2_combined.csv'\n",
    "frame_mfn2_f.to_csv(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da731056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "PCA_DATA = frame_mfn2_f.copy()\n",
    "PCA_DATA.fillna(0, inplace=True)\n",
    "features2 = PCA_DATA.columns[:54]  \n",
    "x2 = PCA_DATA.loc[:, features2].values\n",
    "y2 = PCA_DATA.loc[:,['group']].values\n",
    "x2 = StandardScaler().fit_transform(x2)\n",
    "pd.DataFrame(data = x2, columns = features2).head()\n",
    "pca2 = PCA(n_components=2)\n",
    "principalComponents2 = pca2.fit_transform(x2)\n",
    "PCA_DATA2_COMP = pd.DataFrame(data = principalComponents2\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "importances2 = pd.DataFrame(data = abs(pca2.components_).transpose(), columns = ['PC1', 'PC2'])\n",
    "importances2['Feature'] = features2\n",
    "display(importances2.sort_values('PC1', ascending = False).reset_index(drop = True))\n",
    "imp2 = importances2.sort_values('PC2', ascending = False)[0:30]\n",
    "\n",
    "ax2 = sns.barplot(x = 'PC2', y = 'Feature', data = imp2)\n",
    "fig = ax2.get_figure()\n",
    "fig.set_size_inches(4, 8)\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation = 90)  \n",
    "#plt.savefig(path + '//' + 'drp1_PC2.pdf', dpi = 600)\n",
    "plt.show()\n",
    "    \n",
    "imp4 = importances2.sort_values('PC1', ascending = False)[0:30]\n",
    "ax2 = sns.barplot(x = 'PC1', y = 'Feature', data = imp4)\n",
    "    # Put the legend out of the figure\n",
    "    #plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "fig = ax2.get_figure()\n",
    "fig.set_size_inches(4, 8)\n",
    "ax2.tick_params(axis='x', labelsize=6)\n",
    "ax2.tick_params(axis='y', labelsize=6)\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation = 90)  \n",
    "#plt.savefig(path + '//' 'drp1_PC1.pdf', dpi = 700)\n",
    "plt.show()\n",
    "    \n",
    "PCA_DATA2_FINAL = pd.concat([PCA_DATA2_COMP, PCA_DATA[['group']]], axis = 1)\n",
    "PCA_FIG2 = plt.figure(figsize = (8,8))\n",
    "ax2 = PCA_FIG2.add_subplot(1,1,1) \n",
    "ax2.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax2.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax2.set_title('2 Component PCA', fontsize = 20)\n",
    "ax2.tick_params(axis='x', labelsize=6)\n",
    "ax2.tick_params(axis='y', labelsize=6)\n",
    "for tick in ax2.get_xticklabels():\n",
    "    tick.set_fontname(\"Arial\")\n",
    "for tick in ax2.get_yticklabels():\n",
    "    tick.set_fontname(\"Arial\")\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "targets2 = ['HC', 'S']\n",
    "colors2 = ['b', 'r']\n",
    "for target, color in zip(targets2,colors2):\n",
    "    indicesToKeep = PCA_DATA2_FINAL['group'] == target\n",
    "    ax2.scatter(PCA_DATA2_FINAL.loc[indicesToKeep, 'principal component 1']\n",
    "               , PCA_DATA2_FINAL.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "    ax2.legend(targets2)\n",
    "    ax2.grid()\n",
    "\n",
    "    \n",
    "print(pca2.explained_variance_ratio_)\n",
    "plt.savefig(path + '//' + 'mfn2_PCA2.pdf', dpi = 300)\n",
    "plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3114382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA\n",
    "PCA_DATA_CLEAN = frame_mfn2_f.copy()\n",
    "\n",
    "x = PCA_DATA_CLEAN.loc[:, features2].values\n",
    "y = PCA_DATA_CLEAN.loc[:,['group']].values\n",
    "y = np.array([int('HC' == y_i[0][:2]) for y_i in y])\n",
    "\n",
    "y[0]=2\n",
    "x = StandardScaler().fit_transform(x)\n",
    "\n",
    "lda = LDA(n_components=2)\n",
    "lda_x = np.array(lda.fit(x, y).transform(x))\n",
    "\n",
    "\n",
    "importances = pd.DataFrame(data = abs(lda.scalings_), columns = ['PC1', 'PC2'])\n",
    "importances['Feature'] = features2\n",
    "display(importances.sort_values('PC1', ascending = False).reset_index(drop = True))\n",
    "imp = importances.sort_values('PC2', ascending = False)[0:30]\n",
    "ax1 = sns.barplot(x = 'PC2', y = 'Feature', data = imp)\n",
    "    \n",
    "fig = ax1.get_figure()\n",
    "fig.set_size_inches(4, 8)\n",
    "plt.rc('ytick', labelsize=10)\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), rotation = 90)  \n",
    "#plt.savefig(path + '\\\\' + 'LDA1importancefeat1.pdf', dpi=600)\n",
    "plt.show()\n",
    "imp2 = importances.sort_values('PC1', ascending = False)[0:30]\n",
    "ax2 = sns.barplot(x = 'PC1', y = 'Feature', data = imp2)\n",
    "fig = ax2.get_figure()\n",
    "fig.set_size_inches(4, 8)\n",
    "plt.rc('ytick', labelsize=10)\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation = 90) \n",
    "#plt.savefig(path + '\\\\' + 'LDA1importancefeat2.pdf', dpi=600)\n",
    "plt.show()\n",
    "\n",
    "font = {'family' : 'Arial',\n",
    "        'size'   : 22}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "scale=6\n",
    "target_names= ['S', 'HC']\n",
    "plt.figure()\n",
    "plt.figure(figsize = (8,8))\n",
    "for c, i, target_name in zip(\"rb\", [0, 1], target_names):\n",
    "    plt.scatter(lda_x[y == i,0] , lda_x[y == i,1] , c=c, label=target_name)\n",
    "    plt.legend(target_names*scale,fontsize=12)\n",
    "#     plt.title('LDA of dataset')\n",
    "    plt.xlabel('LD1', fontsize = 20, family = 'Arial')\n",
    "    plt.ylabel('LD2', fontsize = 20, family = 'Arial')\n",
    "    plt.yticks(family = 'Arial', size = 10)\n",
    "    plt.xticks(family = 'Arial', size= 10)\n",
    "print(lda.explained_variance_ratio_)            \n",
    "plt.savefig(path + '\\\\' + 'mfn2-LDA.pdf', dpi=600 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c902f2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "###prepare data for batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a710e659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n",
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n",
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n",
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##drp\n",
    "input_path = 'noam_may_analysis_fold1/DRP1'\n",
    "output_path = 'noam_may_analysis_fold1/DRP1/ready_data_drp1'\n",
    "\n",
    "add_exp_column_to_csv_files(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cfbe9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n",
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n",
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##vat\n",
    "input_path = 'noam_may_analysis_fold1/VAT1'\n",
    "output_path = 'noam_may_analysis_fold1/VAT1/ready_data_VAT1'\n",
    "\n",
    "add_exp_column_to_csv_files(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c99016d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n",
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n",
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n",
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n",
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##mfn1\n",
    "input_path = 'noam_may_analysis_fold1/MFN1'\n",
    "output_path = 'noam_may_analysis_fold1/MFN1/ready_data_MFN1'\n",
    "\n",
    "add_exp_column_to_csv_files(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1ae5dab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n",
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##mfn2\n",
    "input_path = 'noam_may_analysis_fold1/MFN2'\n",
    "output_path = 'noam_may_analysis_fold1/MFN2/ready_data_MFN2'\n",
    "\n",
    "add_exp_column_to_csv_files(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b54b41d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n",
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n",
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n",
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_plate_column('C:/Users/Uri8s/DRP1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72d05322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n",
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n",
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_plate_column('C:/Users/MiguelW12/PycharmProjects/noam_may_analysis_fold1/VAT1/ready_data_VAT1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70117eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n",
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n",
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n",
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n",
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_plate_column('C:/Users/MiguelW12/PycharmProjects/noam_may_analysis_fold1/MFN1/ready_data_MFN1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f716416",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n",
      "C:\\Users\\MiguelW12\\PycharmProjects\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in cast\n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_plate_column('C:/Users/MiguelW12/PycharmProjects/noam_may_analysis_fold1/MFN2/ready_data_MFN2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d207c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ('Results_mito_markers_ready_with_plate')\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "    print('Output folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8051f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drp1\n",
    "all_files = glob.glob('C:/Users/Uri8s/output_drp/*.csv')\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    li.append(df)\n",
    "\n",
    "drp1_df = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0530115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "drp1_df = drp1_df.drop(columns=[\"Timepoint\", \"Time [s]\", \"Plane\", \"Row\", \"Column\", \"Number of Analyzed Fields\", \"Height [µm]\"\n",
    "                               ])\n",
    "drp1_df[\"sample\"] = drp1_df[\"Severity\"].astype(str) + drp1_df[\"Cell ID\"].astype(str) + drp1_df[\"Compound\"].astype(str)  \n",
    "#selected feat\n",
    "drp1_df = drp1_df[[\"spots_chanel_4_final - Corrected Spot Intensity - Mean per Well\",\n",
    "\"spots_chanel_4_final - Intensity_Spot chanel_4_final Mean - Mean per Well\",\n",
    "\"all_cells - chanel_4_Intensity Mean - Mean per Well\", \"total_ir_chanel_4_normalized\",\n",
    "\"modified_spots_chanel_4 - Total Spot Area - Mean per Well\",\n",
    "\"all_cells - chanel_4 Profile 2/5  - Mean per Well\", \"all_cells - chanel_4 SER Spot 1 px - Mean per Well\",\n",
    "\"all_cells - chanel_4 Gabor Max 2 px w2 - Mean per Well\",\n",
    "\"all_cells - chanel_4 SER Edge 1 px - Mean per Well\", \"sample\", \"Severity\", \"Cell ID\", \"Compound\",\n",
    "                  \"all_cells - chanel_1 Ratio Width to Length - Mean per Well\",\n",
    "                  \"all_cells - chanel_1 Roundness - Mean per Well\", \"plate\"]]\n",
    "#rename features\n",
    "drp1_df = drp1_df.rename(\n",
    "     columns={ \"spots_chanel_4_final - Corrected Spot Intensity - Mean per Well\":\"intensity_1\",\n",
    "\"spots_chanel_4_final - Intensity_Spot chanel_4_final Mean - Mean per Well\":\"intensity_2\",\n",
    "\"all_cells - chanel_4_Intensity Mean - Mean per Well\":\"intensity_3\",\n",
    "\n",
    "\"total_ir_chanel_4_normalized\":\"area_1\",\n",
    "\"modified_spots_chanel_4 - Total Spot Area - Mean per Well\": \"area_2\",\n",
    "\"all_cells - chanel_4 Profile 2/5  - Mean per Well\": \"area_3\",\n",
    "\n",
    "\"all_cells - chanel_4 SER Spot 1 px - Mean per Well\": \"texture_1\",\n",
    "\"all_cells - chanel_4 Gabor Max 2 px w2 - Mean per Well\": \"texture_2\",\n",
    "\"all_cells - chanel_4 SER Edge 1 px - Mean per Well\": \"texture_3\" \n",
    "             })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9688fbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "drp1_data_for_batch = drp1_df.groupby(['sample', 'EXP', \"Severity\", \"Cell ID\", \"Compound\", \"plate\"],as_index=False).agg({\n",
    "                                                    'intensity_1':'mean',\n",
    "                                                    'intensity_2':'mean',\n",
    "                                                    'intensity_3':'mean',\n",
    "                                                    'area_1':'mean', \n",
    "                                                    'area_2':'mean',\n",
    "                                                    'area_3':'mean', \n",
    "                                                    'texture_1':'mean',\n",
    "                                                    'texture_2':'mean', \n",
    "                                                    'texture_3':'mean', \n",
    "                                                                })\n",
    "drp1_data_for_batch.columns = [str(col) + '_drp1' for col in drp1_data_for_batch.columns]\n",
    "drp1_data_for_batch = drp1_data_for_batch.rename(\n",
    "     columns={\"sample_drp1\":\"sample\",\n",
    "              \"EXP_drp1\":\"EXP\",\n",
    "              \"plate_drp1\":\"plate\",\n",
    "              \"Severity_drp1\":\"severity\",\n",
    "              \"Cell ID_drp1\":\"cell_id\",\n",
    "              \"Compound_drp1\":\"compound\"\n",
    "             })\n",
    "print(drp1_data_for_batch)\n",
    "drp1_data_for_batch.to_csv(path + \"//\" + 'drp1.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6641b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mfn1\n",
    "all_files = glob.glob('noam_may_analysis_fold1/MFN1/ready_data_mfn1/output/*.csv')\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    li.append(df)\n",
    "\n",
    "mfn1_df = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d84876",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfn1_df = mfn1_df.drop(columns=[\"Timepoint\", \"Time [s]\", \"Plane\", \"Row\", \"Column\", \"Number of Analyzed Fields\", \"Height [µm]\"\n",
    "                               ])\n",
    "mfn1_df[\"sample\"] = mfn1_df[\"Severity\"].astype(str) + mfn1_df[\"Cell ID\"].astype(str) + mfn1_df[\"Compound\"].astype(str)  \n",
    "\n",
    "mfn1_df = mfn1_df[[\"spots_chanel_4_final - Corrected Spot Intensity - Mean per Well\",\n",
    "\"spots_chanel_4_final - Intensity_Spot chanel_4_final Mean - Mean per Well\",\n",
    "\"all_cells - chanel_4_Intensity Mean - Mean per Well\", \"total_ir_chanel_4_normalized\",\n",
    "\"modified_spots_chanel_4 - Total Spot Area - Mean per Well\",\n",
    "\"all_cells - chanel_4 Profile 2/5  - Mean per Well\", \"all_cells - chanel_4 SER Spot 1 px - Mean per Well\",\n",
    "\"all_cells - chanel_4 Gabor Max 2 px w2 - Mean per Well\",\n",
    "\"all_cells - chanel_4 SER Edge 1 px - Mean per Well\", \"sample\", \"EXP\", \"Severity\", \"Cell ID\", \"Compound\", \"plate\"]]\n",
    "#rename features\n",
    "mfn1_df = mfn1_df.rename(\n",
    "     columns={ \"spots_chanel_4_final - Corrected Spot Intensity - Mean per Well\":\"intensity_1\",\n",
    "\"spots_chanel_4_final - Intensity_Spot chanel_4_final Mean - Mean per Well\":\"intensity_2\",\n",
    "\"all_cells - chanel_4_Intensity Mean - Mean per Well\":\"intensity_3\",\n",
    "\n",
    "\"total_ir_chanel_4_normalized\":\"area_1\",\n",
    "\"modified_spots_chanel_4 - Total Spot Area - Mean per Well\": \"area_2\",\n",
    "\"all_cells - chanel_4 Profile 2/5  - Mean per Well\": \"area_3\",\n",
    "\n",
    "\"all_cells - chanel_4 SER Spot 1 px - Mean per Well\": \"texture_1\",\n",
    "\"all_cells - chanel_4 Gabor Max 2 px w2 - Mean per Well\": \"texture_2\",\n",
    "\"all_cells - chanel_4 SER Edge 1 px - Mean per Well\": \"texture_3\" \n",
    "             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5929ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfn1_data_for_batch = mfn1_df.groupby(['sample', 'EXP', \"Severity\", \"Cell ID\", \"Compound\", \"plate\"],as_index=False).agg({\n",
    "                                                    'intensity_1':'mean',\n",
    "                                                    'intensity_2':'mean',\n",
    "                                                    'intensity_3':'mean',\n",
    "                                                    'area_1':'mean', \n",
    "                                                    'area_2':'mean',\n",
    "                                                    'area_3':'mean', \n",
    "                                                    'texture_1':'mean',\n",
    "                                                    'texture_2':'mean', \n",
    "                                                    'texture_3':'mean', \n",
    "                                                                })\n",
    "mfn1_data_for_batch.columns = [str(col) + '_mfn1' for col in mfn1_data_for_batch.columns]\n",
    "mfn1_data_for_batch = mfn1_data_for_batch.rename(\n",
    "     columns={\"sample_mfn1\":\"sample\",\n",
    "              \"EXP_mfn1\":\"EXP\",\n",
    "              \"plate_mfn1\":\"plate\",\n",
    "              \"Severity_mfn1\":\"severity\",\n",
    "              \"Cell ID_mfn1\":\"cell_id\",\n",
    "              \"Compound_mfn1\":\"compound\"\n",
    "             })\n",
    "print(mfn1_data_for_batch)\n",
    "mfn1_data_for_batch.to_csv(path + \"//\" + 'mfn1.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27d610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mfn2\n",
    "all_files = glob.glob('noam_may_analysis_fold1/MFN2/ready_data_mfn2/output/*.csv')\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    li.append(df)\n",
    "\n",
    "mfn2_df = pd.concat(li, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5318cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfn2_df = mfn2_df.drop(columns=[\"Timepoint\", \"Time [s]\", \"Plane\", \"Row\", \"Column\", \"Number of Analyzed Fields\", \"Height [µm]\"\n",
    "                               ])\n",
    "mfn2_df[\"sample\"] = mfn2_df[\"Severity\"].astype(str) + mfn2_df[\"Cell ID\"].astype(str) + mfn2_df[\"Compound\"].astype(str)  \n",
    "\n",
    "mfn2_df = mfn2_df[[\"spots_chanel_4_final - Corrected Spot Intensity - Mean per Well\",\n",
    "\"spots_chanel_4_final - Intensity_Spot chanel_4_final Mean - Mean per Well\",\n",
    "\"all_cells - chanel_4_Intensity Mean - Mean per Well\", \"total_ir_chanel_4_normalized\",\n",
    "\"modified_spots_chanel_4 - Total Spot Area - Mean per Well\",\n",
    "\"all_cells - chanel_4 Profile 2/5  - Mean per Well\", \"all_cells - chanel_4 SER Spot 1 px - Mean per Well\",\n",
    "\"all_cells - chanel_4 Gabor Max 2 px w2 - Mean per Well\",\n",
    "\"all_cells - chanel_4 SER Edge 1 px - Mean per Well\", \"sample\", \"EXP\", \"Severity\", \"Cell ID\", \"Compound\", \"plate\"]]\n",
    "#rename features\n",
    "mfn2_df = mfn2_df.rename(\n",
    "     columns={ \"spots_chanel_4_final - Corrected Spot Intensity - Mean per Well\":\"intensity_1\",\n",
    "\"spots_chanel_4_final - Intensity_Spot chanel_4_final Mean - Mean per Well\":\"intensity_2\",\n",
    "\"all_cells - chanel_4_Intensity Mean - Mean per Well\":\"intensity_3\",\n",
    "\n",
    "\"total_ir_chanel_4_normalized\":\"area_1\",\n",
    "\"modified_spots_chanel_4 - Total Spot Area - Mean per Well\": \"area_2\",\n",
    "\"all_cells - chanel_4 Profile 2/5  - Mean per Well\": \"area_3\",\n",
    "\n",
    "\"all_cells - chanel_4 SER Spot 1 px - Mean per Well\": \"texture_1\",\n",
    "\"all_cells - chanel_4 Gabor Max 2 px w2 - Mean per Well\": \"texture_2\",\n",
    "\"all_cells - chanel_4 SER Edge 1 px - Mean per Well\": \"texture_3\" \n",
    "             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cdecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfn2_data_for_batch = mfn2_df.groupby(['sample', 'EXP', \"Severity\", \"Cell ID\", \"Compound\", \"plate\"],as_index=False).agg({\n",
    "                                                    'intensity_1':'mean',\n",
    "                                                    'intensity_2':'mean',\n",
    "                                                    'intensity_3':'mean',\n",
    "                                                    'area_1':'mean', \n",
    "                                                    'area_2':'mean',\n",
    "                                                    'area_3':'mean', \n",
    "                                                    'texture_1':'mean',\n",
    "                                                    'texture_2':'mean', \n",
    "                                                    'texture_3':'mean', \n",
    "                                                                })\n",
    "mfn2_data_for_batch.columns = [str(col) + '_mfn2' for col in mfn2_data_for_batch.columns]\n",
    "mfn2_data_for_batch = mfn2_data_for_batch.rename(\n",
    "     columns={\"sample_mfn2\":\"sample\",\n",
    "              \"EXP_mfn2\":\"EXP\",\n",
    "              \"plate_mfn2\":\"plate\",\n",
    "              \"Severity_mfn2\":\"severity\",\n",
    "              \"Cell ID_mfn2\":\"cell_id\",\n",
    "              \"Compound_mfn2\":\"compound\"\n",
    "             })\n",
    "print(mfn2_data_for_batch)\n",
    "mfn2_data_for_batch.to_csv(path + \"//\" + 'mfn2.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049c758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vat\n",
    "all_files = glob.glob('noam_may_analysis_fold1/VAT1/ready_data_vat1/output/*.csv')\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    li.append(df)\n",
    "\n",
    "vat_df = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95cb24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vat_df = vat_df.drop(columns=[\"Timepoint\", \"Time [s]\", \"Plane\", \"Row\", \"Column\", \"Number of Analyzed Fields\", \"Height [µm]\"\n",
    "                               ])\n",
    "vat_df[\"sample\"] = vat_df[\"Severity\"].astype(str) + vat_df[\"Cell ID\"].astype(str) + vat_df[\"Compound\"].astype(str)  \n",
    "\n",
    "vat_df = vat_df[[\"spots_chanel_4_final - Corrected Spot Intensity - Mean per Well\",\n",
    "\"spots_chanel_4_final - Intensity_Spot chanel_4_final Mean - Mean per Well\",\n",
    "\"all_cells - chanel_4_Intensity Mean - Mean per Well\", \"total_ir_chanel_4_normalized\",\n",
    "\"modified_spots_chanel_4 - Total Spot Area - Mean per Well\",\n",
    "\"all_cells - chanel_4 Profile 2/5  - Mean per Well\", \"all_cells - chanel_4 SER Spot 1 px - Mean per Well\",\n",
    "\"all_cells - chanel_4 Gabor Max 2 px w2 - Mean per Well\",\n",
    "\"all_cells - chanel_4 SER Edge 1 px - Mean per Well\", \"sample\", \"EXP\", \"Severity\", \"Cell ID\", \"Compound\", \"plate\"]]\n",
    "#rename features\n",
    "vat_df = vat_df.rename(\n",
    "     columns={ \"spots_chanel_4_final - Corrected Spot Intensity - Mean per Well\":\"intensity_1\",\n",
    "\"spots_chanel_4_final - Intensity_Spot chanel_4_final Mean - Mean per Well\":\"intensity_2\",\n",
    "\"all_cells - chanel_4_Intensity Mean - Mean per Well\":\"intensity_3\",\n",
    "\n",
    "\"total_ir_chanel_4_normalized\":\"area_1\",\n",
    "\"modified_spots_chanel_4 - Total Spot Area - Mean per Well\": \"area_2\",\n",
    "\"all_cells - chanel_4 Profile 2/5  - Mean per Well\": \"area_3\",\n",
    "\n",
    "\"all_cells - chanel_4 SER Spot 1 px - Mean per Well\": \"texture_1\",\n",
    "\"all_cells - chanel_4 Gabor Max 2 px w2 - Mean per Well\": \"texture_2\",\n",
    "\"all_cells - chanel_4 SER Edge 1 px - Mean per Well\": \"texture_3\" \n",
    "             })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e844a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vat_data_for_batch = vat_df.groupby(['sample', 'EXP', \"Severity\", \"Cell ID\", \"Compound\", \"plate\"],as_index=False).agg({\n",
    "                                                    'intensity_1':'mean',\n",
    "                                                    'intensity_2':'mean',\n",
    "                                                    'intensity_3':'mean',\n",
    "                                                    'area_1':'mean', \n",
    "                                                    'area_2':'mean',\n",
    "                                                    'area_3':'mean', \n",
    "                                                    'texture_1':'mean',\n",
    "                                                    'texture_2':'mean', \n",
    "                                                    'texture_3':'mean', \n",
    "                                                                })\n",
    "vat_data_for_batch.columns = [str(col) + '_vat' for col in vat_data_for_batch.columns]\n",
    "vat_data_for_batch = vat_data_for_batch.rename(\n",
    "     columns={\"sample_vat\":\"sample\",\n",
    "              \"EXP_vat\":\"EXP\",\n",
    "              \"plate_vat\":\"plate\",\n",
    "              \"Severity_vat\":\"severity\",\n",
    "              \"Cell ID_vat\":\"cell_id\",\n",
    "              \"Compound_vat\":\"compound\"\n",
    "             })\n",
    "print(vat_data_for_batch)\n",
    "vat_data_for_batch.to_csv(path + \"//\" + 'vat.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b9dff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### marker downstream analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c72a1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## markers integ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df754f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##radar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9cdfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_integ = pd.read_csv('all_markers_df_integ.csv')\n",
    "df_integ.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aceeb15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition mapping for the new column\n",
    "condition_mapping = {'M': 'Mild', 'S': 'Severe', 'P': 'Premanifest', 'H': 'Control'}\n",
    "\n",
    "#  create the new column\n",
    "df_integ = create_new_column_based_on_first_letter(df_integ, 'group_with_id', 'group', condition_mapping)\n",
    "df_integ[\"index2\"] = df_integ[\"DS\"].astype(str) + df_integ[\"group_with_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eba010b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_value_to_remove = 'mdivi1 25uM'\n",
    "df_integ = remove_rows_containing_specific_value(df_integ, 'group_with_id', specific_value_to_remove)\n",
    "df_integ = df_integ.groupby(\"group\").mean()\n",
    "df_integ = df_integ.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b935a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_integ.set_index([\"group\"], inplace = True,\n",
    "                            append = True, drop = False)\n",
    "df_integ = df_integ.drop(columns=[\"group\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7478505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale\n",
    "min_max = df_integ.copy()\n",
    "min_max = min_max.reset_index()\n",
    "numeric_columns = min_max.columns[min_max.dtypes == 'float64']\n",
    "group_column = 'group'\n",
    "\n",
    "# Apply Min-Max Scaling\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = min_max.copy()\n",
    "df_scaled[numeric_columns] = scaler.fit_transform(min_max[numeric_columns])\n",
    "df_scaled.set_index([\"group\"], inplace = True,\n",
    "                            append = True, drop = False)\n",
    "df_scaled = df_scaled.drop(columns=[\"group\"])\n",
    "df_scaled = df_scaled + 1\n",
    "df_scaled = df_scaled.drop(columns=[\"level_0\"])\n",
    "df_scaled = df_scaled.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2424c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def radar_plot(df, features, group_column, color_mapping=None):\n",
    "\n",
    "    # Ensure that the provided features are present in the DataFrame\n",
    "    missing_features = set(features) - set(df.columns)\n",
    "    if missing_features:\n",
    "        raise ValueError(f\"The following features are not present in the DataFrame: {missing_features}\")\n",
    "\n",
    "    # Select relevant columns\n",
    "    selected_columns = [group_column] + features\n",
    "    df_selected = df[selected_columns]\n",
    "\n",
    "    # If custom color mapping is provided, use it; otherwise, use default colors\n",
    "    if color_mapping:\n",
    "        color_discrete_map = color_mapping\n",
    "    else:\n",
    "        color_discrete_map = None\n",
    "\n",
    "    # Define dash styles for lines\n",
    "    dash_styles = ['solid', 'dash', 'dot', 'dashdot']\n",
    "\n",
    "    # Create traces for radar polygons\n",
    "    fig = go.Figure()\n",
    "    for i, group in enumerate(df[group_column].unique()):\n",
    "        group_data = df[df[group_column] == group]\n",
    "        fig.add_trace(go.Scatterpolar(\n",
    "            r=group_data[features].mean(),\n",
    "            theta=features,\n",
    "            mode='lines+markers',  # Use 'lines+markers' for filled polygons\n",
    "            name=f'{group} - Mean',\n",
    "            line_shape='linear',\n",
    "            fill='toself',  # Specify 'toself' to fill the polygon\n",
    "            line=dict(color=color_discrete_map[group] if color_discrete_map else None, dash=dash_styles[i % len(dash_styles)]),\n",
    "            marker=dict(color=color_discrete_map[group] if color_discrete_map else None, size=10, symbol='circle'),\n",
    "        ))\n",
    "\n",
    "    # Update layout for better visibility\n",
    "    fig.update_layout(\n",
    "        polar=dict(radialaxis=dict(visible=True, range=[0, df[features].max().max()], tickfont=dict(size=12))),\n",
    "        showlegend=True,\n",
    "        legend=dict(x=0, y=1),  # Move legend to the top-left corner\n",
    "        template='plotly',  # Change the template to 'plotly' for a bright background\n",
    "          # Set background color to light gray\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "    # Define features and group column\n",
    "    features = ['drp1_intensity','mfn1_intensity','mfn2_intensity',\n",
    "              'vat1_intensity']\n",
    "    group_column = 'group'\n",
    "\n",
    "    # Define custom colors for groups (optional)\n",
    "    color_mapping = {'Control': 'blue', 'Severe': 'red',\n",
    "                    'Mild': 'green', 'Premanifest':'yellow'}\n",
    "\n",
    "    # Call the radar plot function\n",
    "    radar_plot(df_scaled, features, group_column, color_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70c8897",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2345df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c0f408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787c44b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
